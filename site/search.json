[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning Portfolio: Gradient Descent",
    "section": "",
    "text": "Welcome\nWelcome to the Deep Learning Portfolio Project.",
    "crumbs": [
      "Home",
      "Welcome"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html",
    "href": "docs/beginner/Perceptron.html",
    "title": "1¬† Perceptron",
    "section": "",
    "text": "1.1 Data generation and visualisation\nThe single-layer perceptron is the simplest neural network, which takes a feature (input), weights it to form a weighted sum, and then passes this to an activation function. The result can then be used for binary classification or linear regression (without activation). It is an ideal starting point for understanding the basic mechanics of neural networks, which we will use to build the foundations of the course.\nObjective of this chapter:\nHow does a neuron process inputs?\nHow do weights influence the decision?\nWhat does ‚Äòlinearly separable‚Äô mean?\nWhy does the perceptron fail with some problems, such as XOR?\nTo begin with, we first create two-dimensional data points based on the logical gates AND / OR. This enables a clear visual representation and shows us immediately whether the data is linearly separable.\nInfo: The perceptron developed by Rosenblatt in 1957 cannot solve linearly non-separable data such as the XOR problem. We take advantage of this property and generate linearly separable and non-separable data sets to reveal the functioning and limitations of the model.\nCreating features and labels\nCode\n# Feautures\nX = np.array([[0,0],[0,1], [1,0], [1,1]], dtype=np.float64)\nprint(f\"Feautures shape: {X.shape}\")\n\n# Labels\ny_and = np.array([[0],[0],[0],[1]], dtype=np.float64)\ny_or = np.array([[0],[1],[1],[1]], dtype=np.float64)\n\ny = y_and\nprint(f\"True y shape: {y.shape}\")\n\n\nFeautures shape: (4, 2)\nTrue y shape: (4, 1)\nNow let‚Äôs look at the visualisation of the data. By looking closely, we can see that they are linearly separable. For illustrative purposes, I will draw a fictitious decision boundary.\nCode\nx_ = np.linspace(0,1,2)\n\ndef visualize_data(X: np.ndarray, y:np.ndarray, title:str):\n    y = y.flatten()\n    fig, ax = plt.subplots(figsize=(7,4))\n    ax.scatter(X[y==0,0], X[y==0,1], color=\"red\", label=\"false\")\n    ax.scatter(X[y==1,0], X[y==1,1], color=\"green\", label=\"true\")    \n    ax.legend()\n    ax.set_xlabel(\"Feature 1\")\n    ax.set_ylabel(\"Feature 2\")\n    ax.set_ylim(-0.1,1.1)\n    ax.set_title(title)\n    ax.grid(ls=\":\", linewidth=0.6)\n    return fig, ax\n\ndef ex_boundary_helper(ax: plt.Axes, intercept:float, x:np.ndarray = x_) -&gt; np.ndarray:\n    y = -x + intercept\n    ax.plot(x,y, ls=\"--\", lw=2, label=\"example decision boundary\")\n    ax.legend()\n\nfig1,ax1 = visualize_data(X, y_and, \"AND\")\nex_boundary_helper(ax1,1.3)\nfig2,ax2 = visualize_data(X, y_or, \"OR\")\nex_boundary_helper(ax2,0.7)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#generierung-der-daten-und-visualisierung",
    "href": "docs/beginner/Perceptron.html#generierung-der-daten-und-visualisierung",
    "title": "1¬† Perzeptron",
    "section": "1.1 Generierung der Daten und Visualisierung",
    "text": "1.1 Generierung der Daten und Visualisierung\nZum Einstieg erstellen wir zun√§chst zweidimenionale Datenpunkten basierend auf den logischen Gattern AND / OR. Das erm√∂glicht eine klare visuelle Darstellung und zeigt uns unmittelbar, ob die Daten linear seperabel sind.\nDas von Rosenblatt entwickelte Perzeptron aus dem Jahr 1957 kann linear nicht seperable Daten wie das XOR Problem nicht l√∂sen. Diese Eigenschaft machen wir uns zu Nutze und erzeugen linear trennbare und nicht trennbare Datens√§tze um die Funktionsweise und Grenzen des Modells sichtbar zu machen.\nErstellen der Feautures und Labels\n\n\nCode\n# Feautures\nX = np.array([[0,0],[0,1], [1,0], [1,1]], dtype=np.float64)\nprint(f\"Feautures shape: {X.shape}\")\n\n# Labels\ny_and = np.array([[0],[0],[0],[1]], dtype=np.float64)\ny_or = np.array([[0],[1],[1],[1]], dtype=np.float64)\n\ny = y_and\nprint(f\"True y shape: {y.shape}\")\n\n\nFeautures shape: (4, 2)\nTrue y shape: (4, 1)\n\n\nNun schauen wir uns die Visualisierung der Daten an, durch scharfes sehen ist erkennbar dass diese linear seperabel sind. Zu illustratorischen Zwecken zeichnen ich uns eine fiktive Entscheidungsgrenze ein.\n\n\nCode\nx_ = np.linspace(0,1,2)\n\ndef visualize_data(X: np.ndarray, y:np.ndarray, title:str):\n    y = y.flatten()\n    fig, ax = plt.subplots(figsize=(7,4))\n    ax.scatter(X[y==0,0], X[y==0,1], color=\"red\", label=\"false\")\n    ax.scatter(X[y==1,0], X[y==1,1], color=\"green\", label=\"true\")    \n    ax.legend()\n    ax.set_xlabel(\"Feature 1\")\n    ax.set_ylabel(\"Feature 2\")\n    ax.set_ylim(-0.1,1.1)\n    ax.set_title(title)\n    ax.grid(ls=\":\", linewidth=0.6)\n    return fig, ax\n\ndef ex_boundary_helper(ax: plt.Axes, intercept:float, x:np.ndarray = x_) -&gt; np.ndarray:\n    y = -x + intercept\n    ax.plot(x,y, ls=\"--\", lw=2, label=\"example decision boundary\")\n    ax.legend()\n\nfig1,ax1 = visualize_data(X, y_and, \"AND\")\nex_boundary_helper(ax1,1.3)\nfig2,ax2 = visualize_data(X, y_or, \"OR\")\nex_boundary_helper(ax2,0.7)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perzeptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#das-perzeptron-als-modell",
    "href": "docs/beginner/Perceptron.html#das-perzeptron-als-modell",
    "title": "1¬† Perceptron",
    "section": "1.2 Das Perzeptron als Modell",
    "text": "1.2 Das Perzeptron als Modell\nDas Perzeptron verarbeitet Eingaben in drei aufeinanderfolgenden Schritten:\n\n1.2.1 1. Eingabe\nDas Modell erh√§lt einen Eingabevektor x, den Featurevektor.\n\n\n1.2.2 2. Berechnung\nDie Eingabe wird √ºber die Gewichte w und den Bias-Parameter b linear transformiert. z nennen wir die gewichtete Summe:\n\\[z = \\mathbf{w}^\\top \\mathbf{x} + b\\]\n\n\n1.2.3 3. Ausgabe\nDie gewichtete Summe z √ºbergeben wir einer nichtlinearen Aktivierungsfunktion, beim Rosenblatt Perceptron klassisch die Step Function. Beim Perzeptron nennen wir das Ergebnis davon die Prediction des Modells:\n\\[\\hat{y} = \\text{step}(z) = \\begin{cases} 1 & \\text{falls } z \\geq 0 \\\\ 0 & \\text{sonst} \\end{cases}\\]\n\n\n1.2.4 Vollst√§ndiger Datenfluss\nDer gesamte Prozess l√§sst sich wie folgt darstellen:\n\\[\\mathbf{x} \\longrightarrow \\mathbf{w}^\\top \\mathbf{x} + b \\longrightarrow \\text{step}(z) \\longrightarrow \\hat{y}\\]\n\n\n\nCode\npth = Path(\"illustrations\") / \"beginner\" / \"perceptron\"\nfig3, ax3 = show_illustration(\n    pth / \"perceptron.ppm\", pth / \"perceptron_source.txt\"\n)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#aktivierungsfunktion-definieren",
    "href": "docs/beginner/Perceptron.html#aktivierungsfunktion-definieren",
    "title": "1¬† Perceptron",
    "section": "1.3 Aktivierungsfunktion definieren",
    "text": "1.3 Aktivierungsfunktion definieren\nNeben der eben definierten Step Function, f√ºhren wir an dieser Stelle die Sigmoid Aktivierungsfunktion ebenfalls ein, welchen wir mit einer modifizierten Lernregel sp√§ter f√ºr das Perzeptron und den Multi Layer Perzeptron verwenden. Im deep learning gibt es eine Vielzahl von verschiedenen Aktivierungen, einige werden wir uns im Verlauf anschauen.\nEine visuelle Inspektion verr√§t uns auf Anhieb schon einige Eigenschaften, welche direkt sichbar sind, zus√§tzlich gibt es versteckte Eigenschaften, welche man nicht durch das scharfe sehen direkt erkennt. F√ºr uns ist das im Moment irrelevant, da wir erstmal eine Intuition zum Workflow bilden wollen. Wir werden das im Kapitel Aktivierung und Featureraum der Beginnersektion n√§her beleuchten und sp√§ter umfassend in der Intermidatesektion.\nSigmoid: \\[ f(x)=\\frac{1}{1+e^{-x}} \\]\nMan erkennt auf Anhieb: - Wertebereich liegt in (0,1) - monoton steigend - f√ºr gro√üe |x| n√§hert sich der Wert 0 oder 1 an - stetig differenzierbar\nDer Ausgabe der Sigmoid-Funktion kann eine Semantik mitgegeben werden. F√ºr die Bin√§rklassifikation bedeutet das: - \\(\\sigma(z) &lt; 0.5\\) ‚Üí Klasse 0 - \\(\\sigma(z) &gt;= 0.5\\) ‚Üí Klasse 1\nStep Function:\nMan erkennt auf Anhieb: - Werte k√∂nnen nur 0 oder 1 annehmen - x = 0 ist nicht definiert - selbst wenn differenzierbar, Steigung = 0 -&gt; kein nutzbarer Gradient -&gt; kein Informationsgehalt\n\n\nCode\ndef step_function(x: np.ndarray):\n  return np.where(x &gt;= 0, 1, 0)\n\ndef sigmoid(x: np.ndarray):\n  return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x: np.ndarray):\n  ds = (np.exp(-x))/(1+np.exp(-x))**2\n  return ds\n\nx = np.linspace(-10, 10, 100)\nfig4, ax4 = plt.subplots(figsize=(7, 4))\n\nax4.plot(x, sigmoid(x), c=\"blue\", label=\"Sigmoid\")\nax4.plot(x, sigmoid_derivative(x), c=\"red\", label=\"Sigmoid derivative\")\nax4.plot(x[x &lt; 0], step_function(x[x &lt; 0]), c=\"orange\", label=\"Step Function\")\nax4.plot(x[x &gt;= 0], step_function(x[x &gt;= 0]), c=\"orange\")\n\nax4.grid(alpha=0.3)\nax4.set_xlabel(\"x\")\nax4.set_ylabel(\"f(x)\")\nax4.legend();",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#perzeptron-klasse-implementieren",
    "href": "docs/beginner/Perceptron.html#perzeptron-klasse-implementieren",
    "title": "1¬† Perceptron",
    "section": "1.4 Perzeptron-Klasse implementieren",
    "text": "1.4 Perzeptron-Klasse implementieren\nNun implementieren wir das Perzeptron als Klasse. Wir haben bereits die Architektur beleuchtet, nun widmen wir uns der Lernregel.\n\n1.4.1 Klassische Perzeptron-Lernregel\nDas Perzeptron lernt, indem es seine Gewichte nur dann anpasst, wenn es einen Fehler macht.\nF√ºr jedes Trainingsbeispiel wird die Prediction \\(\\hat{y}\\) mit dem wahren Label \\(y\\) verglichen.\nDaraus ergibt sich ein Fehlerterm:\n\\[\n\\delta = y - \\hat{y}\n\\]\n\nWenn \\(\\delta = 0\\):\nDie Vorhersage ist korrekt ‚Üí keine Anpassung.\nWenn \\(\\delta = 1\\):\nDas Perzeptron hat \\(0\\) vorhergesagt, obwohl \\(1\\) korrekt w√§re ‚Üí\nDie Gewichte sollen in Richtung von \\(\\mathbf{x}\\) verschoben werden.\nWenn \\(\\delta = -1\\):\nDas Perzeptron hat \\(1\\) vorhergesagt, obwohl \\(0\\) korrekt w√§re ‚Üí\nDie Gewichte sollen von \\(\\mathbf{x}\\) weg verschoben werden.\n\nDie klassische Perzeptron-Lernregel lautet:\n\\[\n\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta \\, \\delta \\, \\mathbf{x}\n\\]\n\\[\nb \\leftarrow b + \\eta \\, \\delta\n\\]\nwobei \\(\\eta\\) die Lernrate ist.\n\n1.4.1.1 Intuition\n\nFalsch klassifizierte positive Beispiele (\\(y = 1\\)) ‚Äûziehen‚Äù den Gewichtsvektor in ihre Richtung.\nFalsch klassifizierte negative Beispiele (\\(y = 0\\)) ‚Äûsto√üen‚Äù den Gewichtsvektor von sich weg.\nKorrekt klassifizierte Beispiele haben keinen Einfluss auf die Gewichte.\n\nAuf diese Weise verschiebt das Perzeptron seine Entscheidungsgrenze so lange, bis alle Trainingspunkte (falls linear separierbar) korrekt klassifiziert werden.\n\n\n\nCode\nclass Perzeptron:\n    def __init__(self, input_size, activation_function):\n\n        self.weight = rng.normal(size=(input_size,1))\n        self.bias = 0.\n        self.activation = activation_function\n\n    def forward(self, X):\n        \"\"\"\n        Berechnet die Ausgabe des Perzeptrons f√ºr ein Feauture X.\n\n        Args:\n            X: Eingabedaten, Shape (n_samples, n_features)\n        Returns:\n            Ausgabe des Perzeptrons nach Aktiverung, Shape (n_samples, 1)\n        \"\"\"\n        z = X @ self.weight + self.bias\n        a = self.activation(z)\n        return a\n\n    def train(self, X, y , lr=0.1, epochs=1000, error_prints=True):\n        \"\"\"\n        Trains the perceptron using the perceptron (error-count) learning rule.\n\n        Args:\n            X (np.ndarray): Input data of shape (n_samples, n_features).\n            y (np.ndarray): Target labels of shape (n_samples, 1) \n            lr (float): Learning rate\n            epochs (int): Maximum number of training epochs.\n            error_prints (bool) : Printing error rates -&gt; set False for timelapse\n\n        Returns:\n            list[float]: List of error_rate per epoch\n            list[float]: List of update_rate per epoch\n        \"\"\"\n    \n        error_history, update_history = [], []\n\n        for epoch in range(epochs):\n            fehler_count = 0\n            for xi, yi in zip(X,y):\n                xi = np.reshape(xi, (1,-1)) # (1, n_features)\n                yi = np.reshape(yi, (-1,1)) # (1, 1) \n                #Forward pass \n                y_hat = self.forward(xi)\n\n                #Calc delta\n                delta = (yi - y_hat)\n                delta = np.squeeze(delta)\n                delta = float(delta)\n\n                #Update weights and bias\n                if delta != 0:\n                    self.weight += lr * delta * xi.T\n                    self.bias += lr * delta\n                    fehler_count += 1\n\n            update_rate = fehler_count/len(y)\n            y_hat = self.forward(X)\n            error_rate = float(np.mean(y != y_hat))\n            error_history.append(error_rate)            \n            update_history.append(update_rate)\n\n            if error_prints:\n                if epoch % 10 == 0:\n                    print(f'Epoch {epoch}: Error Rate = {error_rate:.4f}')\n\n            if error_rate == 0:\n                print(f\"Solution in Epoch {epoch}\")\n                return error_history, update_history\n                \n        return error_history, update_history",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#das-prim√§re-problem",
    "href": "docs/beginner/Perceptron.html#das-prim√§re-problem",
    "title": "1¬† Perceptron",
    "section": "1.5 Das prim√§re Problem",
    "text": "1.5 Das prim√§re Problem\nWir bauen im Laufe des Kurses viele verschiedene Architekturen von Scratch nach. Diese Architekturen werden immer komplexer, und wir werden nicht darum herumkommen, uns mit Bugs und noch schlimmer mit ‚Äûhidden‚Äú Fehlern zu besch√§ftigen, die bsw. durch falsche Shapes oder unerwartetes NumPy-Broadcasting entstehen. Deshalb mal ein beispiel wie ich die von Scratch implementierte Trainingsloop getestet habe.\nBroadcasting kann uns das Leben zwar stark erleichtern und ist oft gut darin zu erraten, was wir meinen, zum Beispiel in einer Zeile wie z = X @ self.w + self.b. Aber genau das kann auch dazu f√ºhren, dass wir Fehler erst sehr sp√§t entdecken, weil der Code zwar l√§uft, aber stillschweigend etwas anderes tut als gedacht.\nLeider haben wir hier nur die Pr√§sentationsschicht, nicht das was live bei mir passiert, deshalb, hier mein pers√∂nliches ‚ÄûGo-to‚Äú, um die Frustration etwas zu senken (ich laufe trotzdem gelegentlich in Bugs rein üòÖ): (Falls ihr Verbesserungen f√ºr mich habt ich bin offen daf√ºr!!!)\nIn unserem Workflow haben wir grob: Daten erstellen ‚Üí Modell definieren ‚Üí Training.\n\nShapes der Daten inspizieren\nSchau dir die Shapes von X und y an:\nEntsprechen sie wirklich dem, was du im Kopf hast?\nZ.B. X.shape == (n_samples, n_features), y.shape == (n_samples, 1).\nShapes des Modells pr√ºfen\nKontrolliere w, b und die Ausgabe von forward:\nPassen die Dimensionen zu deinen Daten? Gibt es offensichtliche Inkonsistenzen?\nDocstrings + Shape-Konventionen festhalten\nSchreib in den Docstring jeder Methode, mit welchen Shapes sie arbeitet\n(z.B. ‚ÄûX: (n_samples, n_features), R√ºckgabe: (n_samples, 1)‚Äú)\nund halte dich daran. Ich habe oben ein kleines Beispiel gegeben.\nDummy-Forward-Pass\nMach einen einzelnen Forward-Pass mit kleinen Dummy-Daten\n(z.B. 1‚Äì2 Samples) und pr√ºfe nur die Shapes der Zwischenwerte:\nprint(X.shape, w.shape, z.shape, a.shape, ...).\nAssertions & Prints im Training Weil wir unsere eigene traningsloop hier von scratch definieren -&gt; Simuliere den Trainingsloop.\nBaue unmengen an assert-Statements ein (z.B. assert y.shape == y_hat.shape)\nund debug-Prints, um zu pr√ºfen, ob die Berechnungen stimmen.\nKlein anfangen\nTeste neue Architektur-Ideen welche du von scratch nachabauen willst mit kleinen Modellarchitekturen, baue dein Code Modular und erweitere dann.\nRestart Session Wenn du mit ipynb Dateien wie hier arbeitest, starte die Umgebung neu, um die Umgebungsvariablen zu l√∂schen. Diesen Fehler habe ich am h√§ufigsten bei anderen beobachtet.\nDebugger Der Debugger dient f√ºr mich als letzte Bastion. F√ºr Beginner empfehle ich Thonny daf√ºr (will keine Werbung machen XD).\nKonsole Nutze die Konsole um schnelle √úberpr√ºfungen zu machen.\n\n\n1.5.1 Fazit\nSchreibe deine tests, hier also ein besipiel von mir, sp√§ter kann man das auch noch mit pytests erg√§nzen aber f√ºr Anf√§nger in python sollte so eine Struktur erstmal reichen.\n\n\nCode\ndef test_train(model:Perzeptron, X:np.ndarray, y:np.ndarray , lr=0.1, epochs=1):\n    \"\"\"\n    Trains the perceptron using the perceptron (error-count) learning rule.\n\n    Args:\n        X (np.ndarray): Input data of shape (n_samples, n_features).\n        y (np.ndarray): Target labels of shape (n_samples, 1) \n        lr (float): Learning rate\n        epochs (int): Maximum number of training epochs.\n\n    Returns:\n        list[float]: List of error_rate per epoch\n        list[float]: List of update_rate per epoch\n    \"\"\"\n    print(\"=== Dummy train debug ===\")\n    error_history, update_history = [], []\n    # Checks before loop\n    print(f\"X.shape = {X.shape}\")\n    print(f\"y.shape = {y.shape}\")\n    assert X.ndim == 2, \"X should be 2D: (n_samples, n_features)\"\n    assert y.ndim == 2, \"y should be 2D: (n_samples, 1)\"\n    assert X.shape[0] == y.shape[0], \"X and y must have the same number of samples\"\n\n    print(f\"model.w.shape = {model.weight.shape}\")\n    print(f\"model.b type  = {type(model.bias)}\")\n    \n    for epoch in range(epochs):\n        fehler_count = 0\n\n        for i, (xi, yi) in enumerate(zip(X, y)):\n            # Check xi yi shapes f.e without reshape yi has shape (1,)\n            print(f\"--- Sample {i} ---\")\n            xi = np.reshape(xi, (1, -1))   # (1, n_features)\n            yi = np.reshape(yi, (-1, 1))   # (1, 1)\n\n            print(f\"xi.shape: {xi.shape}, yi.shape: {yi.shape}\")\n            print(f\"xi: {xi}\")\n            print(f\"yi: {yi}\")\n\n            # Check Forward-Pass\n            y_hat = model.forward(xi)\n            print(f\"y_hat.shape: {y_hat.shape}\")\n            print(f\"y_hat: {y_hat}\")\n\n            assert yi.shape == (1, 1)\n            assert yi.shape == y_hat.shape, \"yi and y_hat must have the same shape\"\n            # Correctness of the output step function\n            assert np.all((y_hat == 0) | (y_hat == 1)), \"y_hat should be 0 or 1 for step activation\"\n\n            # Delta check\n            delta = yi - y_hat\n            print(f\"delta: {delta}, shape: {delta.shape}\")\n            delta = np.squeeze(delta)\n            delta = float(delta)\n            \n            # Update check\n            if delta != 0:\n                print(\"updating parameters\")\n                print(f\"w before update: {model.weight}\")\n                print(f\"b before update: {model.bias}\")\n\n                update_w = lr * delta * xi.T    # (n_features, 1)\n                assert update_w.shape == model.weight.shape\n\n                model.weight += update_w\n                model.bias += lr * delta\n\n                print(f\"w after update: {model.weight}\")\n                print(f\"b after update: {model.bias}\")\n\n                fehler_count += 1\n            else:\n                print(\"Correct classification, no update\")\n\n        update_rate = fehler_count/len(y)\n        y_hat = model.forward(X)\n        error_rate = float(np.mean(y != y_hat))\n        assert 0 &lt;= error_rate &lt;= 1, \"error_rate must be between 0 and 1\"\n\n        # Output type check even if np object would work too\n        assert isinstance(error_rate, (float)), \"error_rate must be float\"\n        assert isinstance(update_rate, (float)), \"update_rate must float)\"\n\n    print(\"=== End dummy ===\")\n\n\ntest_model = Perzeptron(X.shape[1], step_function)\ntest_train(test_model, X, y)\n\n\n=== Dummy train debug ===\nX.shape = (4, 2)\ny.shape = (4, 1)\nmodel.w.shape = (2, 1)\nmodel.b type  = &lt;class 'float'&gt;\n--- Sample 0 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[0. 0.]]\nyi: [[0.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[-1.]], shape: (1, 1)\nupdating parameters\nw before update: [[0.55326059]\n [0.21760061]]\nb before update: 0.0\nw after update: [[0.55326059]\n [0.21760061]]\nb after update: -0.1\n--- Sample 1 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[0. 1.]]\nyi: [[0.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[-1.]], shape: (1, 1)\nupdating parameters\nw before update: [[0.55326059]\n [0.21760061]]\nb before update: -0.1\nw after update: [[0.55326059]\n [0.11760061]]\nb after update: -0.2\n--- Sample 2 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[1. 0.]]\nyi: [[0.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[-1.]], shape: (1, 1)\nupdating parameters\nw before update: [[0.55326059]\n [0.11760061]]\nb before update: -0.2\nw after update: [[0.45326059]\n [0.11760061]]\nb after update: -0.30000000000000004\n--- Sample 3 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[1. 1.]]\nyi: [[1.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[0.]], shape: (1, 1)\nCorrect classification, no update\n=== End dummy ===\n\n\n\n\n1.5.2 Perzeptron trainieren\nJetzt k√∂nnen wir das Modell auf unseren AND/OR-Daten trainieren.\nDabei interessiert uns nicht nur, ob das Perzeptron am Ende alles richtig klassifiziert, sondern auch, wie sich die Fehlerrate (Error Rate) √ºber die Epochen entwickelt.\nDie Error Rate ist dabei einfach der Anteil der Trainingsbeispiele, die in einer Epoche falsch klassifiziert wurden.\nDaf√ºr visualisieren wir den Verlauf der Error Rate w√§hrend des Trainings.\n\n\nCode\ndef visualize_training(error_history):\n    epochs = np.arange(1, len(error_history) + 1)\n    fig, ax = plt.subplots(figsize=(7, 4))\n\n    ax.plot(epochs,error_history, label=\"Error rate\", c=\"r\")\n    ax.set_xlabel(\"Epoch\")\n    ax.set_ylabel(\"Error rate\")\n    ax.set_title(\"Error rate progress\")\n    ax.legend()\n    return fig, ax\n\n\n\n\n\nCode\ninput_size = X.shape[1]\nmodel = Perzeptron(input_size, step_function)\nerror_history,_ = model.train(X, y, lr=0.1, epochs=100)\nfig5, ax5 = visualize_training(error_history)\n\n\nEpoch 0: Error Rate = 0.7500\nEpoch 10: Error Rate = 0.5000\nEpoch 20: Error Rate = 0.5000\nSolution in Epoch 25",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#ergebnisse-auswerten",
    "href": "docs/beginner/Perceptron.html#ergebnisse-auswerten",
    "title": "1¬† Perceptron",
    "section": "1.5 Ergebnisse auswerten",
    "text": "1.5 Ergebnisse auswerten\nNun schauen wir uns an wie das trainierte Perzeptron auf die Eingabedaten reagiert. Manchen Lesern wird sofort klar sein, dass die Predictions und Erwartete Ausgabe identisch sein m√ºssen, da eine L√∂sung vor der Abbruchbedinung gefunden wurde. Die Error rate f√ºr dieses Modell kann nur die Werte: 1 (max Fehlerz√§hler/4) 0.75 3/ 4 0.5 2/4 0.25 1/4 0 0/4 annehmen\n\n\nCode\npredictions = model.forward(X)\nprint(\"Eingaben und Vorhersagen:\")\nfor i in range(len(X)):\n    print(f\"Eingabe: {X[i]}, Erwartete Ausgabe: {y[i]}, Vorhersage: {predictions[i]}\")\n\n\nEingaben und Vorhersagen:\nEingabe: [0. 0.], Erwartete Ausgabe: [0.], Vorhersage: [0]\nEingabe: [0. 1.], Erwartete Ausgabe: [0.], Vorhersage: [0]\nEingabe: [1. 0.], Erwartete Ausgabe: [0.], Vorhersage: [0]\nEingabe: [1. 1.], Erwartete Ausgabe: [1.], Vorhersage: [1]",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#das-mathematische-modell",
    "href": "docs/beginner/Perceptron.html#das-mathematische-modell",
    "title": "1¬† Perceptron",
    "section": "1.6 Das mathematische Modell",
    "text": "1.6 Das mathematische Modell\nDas trainierte Perzeptron k√∂nnen wir und als Funktion ausgeben lassen. Das dient zur Verst√§ndnisbildung, denn neuronale Netze egal ob tief oder nicht sind nichts anderes als mathematische Modelle. Weil das Perzeptron so simpel ist kann man sich das ausgeben lassen, normalerweise untersucht man die gelernten gewichte und den bias. Aber das machen wir in einem sp√§terem Kapitel.\n\n\nCode\nw_flat = model.weight.flatten()  \nw1, w2 = w_flat\nb = model.bias\nprint(f\"f(x1,x2) = step({w1:.3f}*x1 + {w2:.3f}*x2 + {b:.3f})\")\n\n\nf(x1,x2) = step(0.142*x1 + 0.081*x2 + -0.200)\n\n\n\n1.6.1 Entscheidungsgrenze visualisieren\nDie Entscheidungsgrenze ist hier die Gerade im Feature-Raum, an der das Perzeptron von Klasse 0 auf Klasse 1 ‚Äûumschaltet‚Äú. F√ºr ein Perzeptron mit zwei Eingaben ist das eine Gerade, die wir bereits oben beschrieben haben.\nWir visualisieren die Entscheidungsgrenze, indem wir auf einem Raster von Punkten (meshgrid) die Vorhersagen des Modells berechnen und mit contourf darstellen. Dadurch sieht man:\n\nDie Vorhersage springt von 0 auf 1. Es gibt keine Werte dazwischen, das sehen wir auch durch die colorbar.\nDie Grenze wirkt immer treppenf√∂rmiger mit kleinerem n, weil wir nur auf einem Gitter auswerten. Das widerspricht auf dem erstem Blick der definierten Funktion, aber dass sind halt die Grenzen eines Plotters. Bei meinem eigenem Funktionsplotter den ich programmiert hatte, hatte ich ebenfalls das selbe Problem.\n\n\n\nCode\nn = 1000\nx1 = np.linspace(-0.1, 1.1, n)\nx2 = np.linspace(-0.1, 1.1, n)\nx1_grid, x2_grid = np.meshgrid(x1, x2)\nX_viz = np.c_[x1_grid.flatten(), x2_grid.flatten()]\nassert X_viz.shape == (n*n, 2), (\n    \"Shape Mismatch for forward pass -&gt; expect shape (samplesize,2)\"\n    )\n\ny_viz = model.forward(X_viz).reshape(n,-1)\nfig6, ax6 = visualize_data(X,y,\"Descision Boundary Step Function for AND\")\ncf = ax6.contourf(x1_grid, x2_grid, y_viz, levels=10, cmap='coolwarm', alpha=0.6, zorder=0)\nfig6.colorbar(cf, label=\"Prediction\");",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#training-f√ºr-das-or-problem",
    "href": "docs/beginner/Perceptron.html#training-f√ºr-das-or-problem",
    "title": "1¬† Perceptron",
    "section": "1.7 Training f√ºr das OR-Problem",
    "text": "1.7 Training f√ºr das OR-Problem\nInspizieren wir das auch f√ºr das Or-Problem. Da dies wie zu Beginn festgestellt ebenfalls linear seperabel ist,wird ebenfalls eine L√∂sung gefunden.\n\n\nCode\ny = y_or\nmodel = Perzeptron(input_size, step_function)\nerror_history,_ = model.train(X, y, lr=0.1, epochs=100)\nfig7, ax7 = visualize_training(error_history)\n\n\nEpoch 0: Error Rate = 0.7500\nEpoch 10: Error Rate = 0.5000\nEpoch 20: Error Rate = 0.2500\nSolution in Epoch 23\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_viz = model.forward(X_viz).reshape(n,-1)\nfig8, ax8 = visualize_data(X,y,\"Descision Boundary Step Function for OR\")\ncf = ax8.contourf(x1_grid, x2_grid, y_viz, levels=10, cmap='coolwarm', alpha=0.6, zorder=0)\nfig8.colorbar(cf, label=\"Prediction\");",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#problem-xor",
    "href": "docs/beginner/Perceptron.html#problem-xor",
    "title": "1¬† Perceptron",
    "section": "1.8 Problem Xor",
    "text": "1.8 Problem Xor\nSo far, we have looked at the behaviour of the perceptron for linearly separable data. We will now examine the limitations of the perceptron by replicating the problem mentioned at the beginning. When visualising the data, it quickly becomes clear that we cannot find a linear decision boundary that separates the data linearly. The lowest achievable error rate is 0.25.\n\n\nCode\ny_xor = np.array([[0],[1],[1],[0]], dtype=np.float64)\ny = y_xor\nprint(f\"y_xor shape: {y.shape}\")\nfig9, ax9 = visualize_data(X,y, \"Xor - Problem\")\n\n\ny_xor shape: (4, 1)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel = Perzeptron(input_size,activation_function=step_function)\nerror_history, update_history = model.train(X, y, lr=0.1, epochs=100)\nfig10, ax10 = visualize_training(error_history)\n\n\nEpoch 0: Error Rate = 0.2500\nEpoch 10: Error Rate = 0.5000\nEpoch 20: Error Rate = 0.5000\nEpoch 30: Error Rate = 0.5000\nEpoch 40: Error Rate = 0.5000\nEpoch 50: Error Rate = 0.5000\nEpoch 60: Error Rate = 0.5000\nEpoch 70: Error Rate = 0.5000\nEpoch 80: Error Rate = 0.5000\nEpoch 90: Error Rate = 0.5000\n\n\n\n\n\n\n\n\n\nLet us now examine why the error rate converges towards 0.5. We can create a time lapse to quickly illustrate the shift in decision boundaries. In addition, we will examine the updating of model parameters and the update rate across epochs.\n\n\nCode\ny_viz = model.forward(X_viz).reshape(n,-1)\nfig11, ax11 = visualize_data(X,y,\"Descision Boundary Step Function for XOR\")\ncf = ax11.contourf(x1_grid, x2_grid, y_viz, levels=10, cmap='coolwarm', alpha=0.6, zorder=0)\nfig11.colorbar(cf, label=\"Prediction\");\n\n\n\n\n\n\n\n\n\n\n\nCode\ndemo_model = Perzeptron(input_size,activation_function=step_function)\n\nfig12, ax12 = visualize_data(X,y,\"Descision Boundary Over Time for XOR\")\nweight_histoy, bias_history = [], []\nerror_history, update_history = [], []\ndemo_viz = demo_model.forward(X_viz).reshape(n, -1)\ndemo_contour = ax12.contourf(\n    x1_grid, x2_grid, demo_viz,\n    levels=10, cmap=\"coolwarm\", alpha=0.6, zorder=0\n)\nplt.close(fig12)\n\n\n\nC:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29568\\2921184144.py:11: UserWarning: Adding colorbar to a different Figure &lt;Figure size 700x400 with 3 Axes&gt; than &lt;Figure size 700x400 with 1 Axes&gt; which fig.colorbar is called on.\n  fig12.colorbar(cf, label=\"Prediction\");\n\n\n\n\nCode\ndef update(frame):\n    global demo_contour\n    global weight_histoy, bias_history\n    global error_history, update_history\n    demo_contour.remove()\n    error, update = demo_model.train(X, y, lr=0.1, epochs=1, error_prints=False)\n    \n    weight_histoy.append(demo_model.weight.copy())\n    bias_history.append(demo_model.bias)\n    error_history.append(error[-1])\n    update_history.append(update[-1])\n    demo_viz = demo_model.forward(X_viz).reshape(n, -1)\n    demo_contour = ax12.contourf(\n        x1_grid, x2_grid, demo_viz,\n        levels=10, cmap=\"coolwarm\", alpha=0.6, zorder=0\n    )\n    ax12.set_title(f\"Decision Boundary ‚Äì Epoch {frame+1}\")\n    return []\n\nani = animation.FuncAnimation(fig12, update, frames=100, interval=200, blit=False)\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nCode\nweight_histoy = np.array(weight_histoy)\nw1 = weight_histoy[:,0,0]\nw2 = weight_histoy[:,1,0]\nw1.shape\n\n\n(101,)\n\n\n\n\nCode\nfig13, axs = plt.subplots(2,2,figsize=(14,8))\nax13_er, ax13_up, ax13_w, ax13_b = axs.flatten()\nax13_er.plot(error_history,c=\"r\", label=\"Error Rate\")\nax13_er.set_title(\"Error Rate\")\nax13_up.plot(update_history, label=\"Update Rate\")\nax13_up.set_title(\"Update Rate\")\nax13_w.plot(w1, label=\"Weight 1\")\nax13_w.plot(w2, label=\"Weight 2\", c=\"orange\")\nax13_w.set_title(\"Weight History\")\nax13_b.plot(bias_history, label=\"Bias\")\nax13_b.set_title(\"Bias\")\nfig13.legend();",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html",
    "title": "2¬† Introduction Gradient Descent",
    "section": "",
    "text": "2.1 1. Datengenerierung\nIn diesem Notebook werden wir das Konzept des Gradientenabstiegs anhand einer linearen Regression erarbeiten. Wir starten mit der Generierung von synthetischen Daten, definieren unser Modell und die Kostenfunktion (Loss Function) und implementieren anschlie√üend den Optimierungsalgorithmus Schritt f√ºr Schritt.\nWhat to do next - Mit Abschluss dieses Notebooks werden die Grundlagen gelegt um im n√§chsten Chapter die Grenzen des GD zu verstehen bei nicht linearen Feauturedimensionen und R√§umen. - Start with the Backpropagation Chapter\nZuerst generieren wir synthetische Daten, die einer linearen Beziehung folgen: \\(y = wx + b + \\epsilon\\). Dabei f√ºgen wir ein Rauschen (Noise) \\(\\epsilon\\) hinzu, um reale Bedingungen zu simulieren.\nCode\ntrue_m = 2\ntrue_b = 2\nnum_gen_values = 1000\nx = np.linspace(-5,5, num_gen_values) # no linkage term in MSE without noise\ntrue_y = true_m * x + true_b\nsigma = 0.9\nwhite_noise = rng.normal(0.0, sigma, num_gen_values)\nobserved_y = true_y + white_noise",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#datenvisualisierung",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#datenvisualisierung",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.2 2. Datenvisualisierung",
    "text": "2.2 2. Datenvisualisierung\nVisualisierungen der Daten helfen uns einen Verst√§ndnis zu unseren Daten zu bilden, Probleme Fr√ºhzeitig zu erkennen und vieles mehr.\n\n\nCode\ndef viz_data(viz_func,x_func, x_split, y_split,predlabel,func_label=\"true\"):\n  fig, ax = plt.subplots(figsize=(7,4))\n  ax.plot(x, viz_func, c=\"green\", label=func_label)\n  ax.scatter(x_split, y_split, s=3, c=\"red\", label=predlabel)\n  ax.legend()\n  ax.grid()\n  return fig, ax\n\nfig0, ax0 = viz_data(true_y,x,x,observed_y,\"noise\")",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#generierung-der-training-und-validierungsdaten",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#generierung-der-training-und-validierungsdaten",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.3 3. Generierung der Training und Validierungsdaten",
    "text": "2.3 3. Generierung der Training und Validierungsdaten\nAus unseren synthetisch erzeugten Daten erstellen wir ein Trainings und Validierungsplit, um das Modell auf einem Teil der Daten zu trainieren und seine F√§higkeit zur Generalisierung auf bisher ungesehene Daten zu √ºberpr√ºfen.\n\n\nCode\ndef split(x,y,val_size=0.2, n=num_gen_values):\n  idx = rng.permutation(n)\n  n_val = int((n* val_size))\n  n_train = n - n_val\n  train_idx = idx[:n_train]\n  val_idx = idx[n_train:]\n  x_train, x_val = x[train_idx], x[val_idx]\n  y_train, y_val = y[train_idx], y[val_idx]\n  return x_train, x_val, y_train, y_val, train_idx, val_idx\n\n\n\n\nCode\nx_train, x_val, y_train, y_val, t_idx, v_idx = split(x,observed_y)\n\nfig1, ax1 = viz_data(true_y,x,x_train,y_train,\"train data\")\nfig2, ax2 = viz_data(true_y,x,x_val,y_val,\"val data\")",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#zuf√§llige-initialisierung-der-modellparameter",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#zuf√§llige-initialisierung-der-modellparameter",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.4 4. Zuf√§llige Initialisierung der Modellparameter",
    "text": "2.4 4. Zuf√§llige Initialisierung der Modellparameter\nWir initilalsieren die Parameter w und b zuf√§llig.\n\n\nCode\nw = rng.random()\nb = rng.random()\n\ndef predict(x,w,b):\n  y_hat = w * x + b\n  return y_hat\n\ny_hat = predict(x_train,w,b)\n\nprint(f\"zuf√§llige Initialisierung mit Steigung von: {w} und Achsenabschnitt {b}\")\n\n\nzuf√§llige Initialisierung mit Steigung von: 0.507637862250508 und Achsenabschnitt 0.8148854343292782\n\n\nPlotten wir nun die Prediction y_hat mit unseren zuf√§lligen Parametern.\n\n\nCode\nax1.scatter(x_train,y_hat, color=\"blue\", label=\"random model\", s=1)\nax1.legend()\nfig1",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#lossfunction",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#lossfunction",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.5 5.Lossfunction",
    "text": "2.5 5.Lossfunction\nWir k√∂nnen direkt erkennen, dass unsere zuf√§llig generierte Funktion die Daten nicht gut abbildet. Um das zu quantifizieren, brauchen wir eine Verlustfunktion.\nF√ºr das Regressionsproblem, welches wir l√∂sen wollen, halten wir es simpel mit dem Mean Squared Error. Wie man in der Summenschreibweise erkennt, gibt es bei unserem linearen Modell einen Kopplungsterm \\(2 \\cdot b \\cdot w \\cdot \\sum(x)\\). Durch das Zentrieren von \\(x\\) wird die Summe 0 und somit f√§llt der Term sp√§ter weg. Bei unseren Daten mit Rauschen wird dieser kleiner und auch somit der Einfluss von \\(w\\) auf \\(b\\) in Bezug auf das MSE und vice versa.\n\\[\n\\begin{aligned}\n\\displaystyle\nMSE &= \\frac{1}{n} \\sum\\limits_{i=1}^{n} error_i^2 \\\\[8pt]\n    &= \\frac{1}{n} \\sum\\limits_{i=1}^{n} (\\hat{y}_i - y_i)^2 \\\\[8pt]\n    &= \\frac{1}{n} \\sum\\limits_{i=1}^{n} (b + w x_i - y_i)^2 \\\\[8pt]\n    &= \\frac{1}{n} \\Bigg(\n        \\sum\\limits_{i=1}^{n} y_i^2\n        - 2b \\sum\\limits_{i=1}^{n} y_i\n        - 2w \\sum\\limits_{i=1}^{n} x_i y_i\n        + b^2 n\n        + {\\color{red}{2bw \\sum\\limits_{i=1}^{n} x_i}}\n        + w^2 \\sum\\limits_{i=1}^{n} x_i^2\n      \\Bigg)\n\\end{aligned}\n\\]\nAls n√§chstes setzen wir den Error √ºber den Trainingsdatensatz in unsere Funktion ein, hier √ºber error = (yhat-y).\n\n\nCode\ndef mse(y, y_hat):\n  return (1/len(y)) * np.sum((y_hat-y)**2)\n\ndef dmse_dyhat(y,y_hat):\n  return (2/y.size) * (y_hat-y)\n\nloss = mse(y_train,y_hat)\nprint(loss)\n\n\n20.28441569406824\n\n\nAuch wenn manche direkt durch scharfes sehen erkennen, dass gro√üe Au√ürei√üer in unseren Daten st√§rker in den MSE einflie√üen, macht es Sinn sich die Funktion plotten zu lassen, sodass man auf Anhieb auch erkennt wieso. Der √úbertrag zum Gradientenabstieg (dazu gleich mehr) findet statt wenn man auch die Ableitung der Funktion genauer anschaut damit man auch den Einfluss der Lossfunction auf den Graidenten erkennt.\nH√§ufig wird die Fehlannahme getroffen man k√∂nnte ein Datensatz einfach explorieren und Au√ürei√üer entfernen, jedoch kann man damit sehr schnell fehlannahen treffen. Im Beispiel der Biologie wird dass schnell deutlich, sehr h√§ufig haben gleiche Blutproben die man zur Untersuchung in unterschiedliche Labore schickt, unterschiedliche Blutwerte. Dass kann durch unterschiedliche Messmethoden, schlechter K√ºhlung beim Transport oder intrinsichen Reaktionen entstehen. Unser Modell soll lernen mit rauschen umzugehen. Nat√ºrlich bedeutet es nicht das man offensichtliche Messfehler bereinigen sollte. Aber es ist ein heikles Thema da meist Dom√§nenwissen erforderlich ist.\nFindige Leser werden sofort √ºber eine Methodik nachdenken wie man z.B durch skalierende Transformationen und Normalisierungsverfahren den MSE besser unter Kontrolle h√§lt. Das werden wir in einem anderen Kapitel genauer behandeln.\nIn unserem zweiten Plott w√ºrden wir auch sofort den einfluss vom MSE auf den Gradientenabstieg erkennen. Gro√üe Residuen f√ºhren zu hohen Steigungen im Fehlerterm, was wiederum zu gro√üen Gradienten f√ºhrt. Ein Teufelskreislauf.\n\n\nCode\nviz_true_y = np.zeros(1)\nviz_range_y = np.linspace(-10,10, 100)\nviz_mse = [mse(viz_true_y,i) for i in viz_range_y]\nviz_dmse = [dmse_dyhat(viz_true_y,i) for i in viz_range_y]\n\nfig3, (ax3,ax4) = plt.subplots(1,2,figsize=(14,4))\n\nax3.plot(viz_range_y, viz_mse, c=\"r\")\nax3.set_ylabel(\"MSE\")\nax3.set_xlabel(\"Error\")\nax3.set_title(\"MSE Function\")\nax3.grid()\n\nax4.plot(viz_range_y, viz_dmse, c=\"r\")\nax4.set_ylabel(\"dMSE\")\nax4.set_xlabel(\"Error\")\nax4.set_title(\"MSE partial derivate\")\nax4.grid()\n\n\n\n\n\n\n\n\n\nF√ºr Simulationszwecke wird nun eine kleine Klasse angelegt, um sp√§ter bei der Visualisierung Coderedundazen zu vermeiden. Diese Zelle kann gerne √ºbersprungen werden.\n\n\nCode\nclass Calculator():\n  def __init__(self, x: np.ndarray, y: np.ndarray, start_axis=0, stop_axis=4):\n    try:\n      assert x.size == y.size, \"Shape missmatch, can cause Problems later\"\n    except AssertionError as error:\n      print(error)\n    self.x = x\n    self.y = y\n    #Terms\n    self.Syy = np.sum(y**2)\n    self.Sxy = np.sum(y * x)\n    self.Sxx = np.sum(x**2)\n    self.Sx = np.sum(x)\n    self.Sy = np.sum(y)\n    self.n = len(y)\n\n    #axis\n    self.w_axis : np.ndarray | None = None\n    self.b_axis : np.ndarray | None = None\n    self.w_mesh : np.ndarray | None = None\n    self.b_mesh : np.ndarray | None = None\n    self.set_mesh(start_axis,stop_axis)\n\n  def mse(self, w = None, b = None, is_mesh=False):\n    if w is not None and b is not None:\n      w = np.asarray(w)\n      b = np.asarray(b)\n    elif (w is None) != (b is None):\n      raise ValueError(\"w or b value missing\")\n    else:\n      if not is_mesh:\n          w = self.w_axis\n          b = self.b_axis\n      else:\n        w = self.w_mesh\n        b = self.b_mesh\n\n    term = (self.Syy - 2*w*self.Sxy - 2*b*self.Sy + w**2 * self.Sxx\n            + 2*w*b*self.Sx + self.n*(b**2) )\n    mse = term/self.n\n    return mse\n\n\n  def grad_b(self,w,b):\n    term = (- 2*self.Sy\n            + 2*w*self.Sx + 2*self.n*(b))\n    dmse_db = term/self.n\n    return dmse_db\n\n  def grad_w(self,w,b):\n    term = (- 2*self.Sxy + 2 * w * self.Sxx\n            + 2*b*self.Sx )\n    dmse_dw = term/self.n\n    return dmse_dw\n\n  def set_mesh(self,start,stop, n=1):\n    if n == 1:\n      n = self.n\n    self.w_axis = np.linspace(start,stop,n)\n    self.b_axis = np.linspace(start,stop,n)\n    self.w_mesh, self.b_mesh = np.meshgrid(self.w_axis,self.b_axis)\n\n\n\nNun schauen wir uns den Einfluss unsere Modellparameter w und b bez√ºglich des MSE anhand unserer Trainingsdaten an wir k√∂nnen dabei folgende Annahmen treffen:\n\nDer Bias Term hat mit unseren Feautures und dem linearen Modell einen schw√§cheren Einfluss als w -&gt; Additiv vs Multiplikativ. Eine Skalierung, Transformation bsw. der Feautures (x Werte), kann das nat√ºrlich √§ndern.\nDurch das hinzuf√ºgen von normalverteilten Rauschen ist der Fehler selbst bei wahren Parametern nicht mehr 0 (true_m, true_b) . Das hei√üt unsere optimalen Modell Parameter unterscheiden sich von den ‚Äúwahren‚Äù Werten. (Analytische Berechnung zum Schluss)\nAus 2. Das Minimum der Fehlerfunktion ist nicht 0.\n\n\n\nCode\nterm = Calculator(x_train, y_train)\nmse_value = term.mse(term.w_mesh,term.b_mesh)\n\ndef surface_3d(w_mesh, b_mesh, mse, title, dpi=200, z_lim=None):\n  fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n  surf = ax.plot_surface(w_mesh, b_mesh, mse, cmap=cm.coolwarm,\n                       linewidth=0, antialiased=True,\n                       zsort='average')\n  if z_lim is not None:\n    ax.set_zlim(z_lim)\n  ax.zaxis.set_major_formatter('{x:.02f}')\n  fig.colorbar(surf, shrink=0.5, aspect=5)\n  ax.zaxis.set_major_locator(LinearLocator(10))\n  ax.set_title(title)\n  ax.set_xlabel(\"w\")\n  ax.set_ylabel(\"b\")\n  return fig, ax\n\ndef mse_contour(\n    w_axis, b_axis, mse, w_pred, b_pred,true_m=true_m, true_b=true_b,\n):\n  fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,4))\n  cf = ax1.contourf(w_axis,b_axis, mse, levels=8)\n  c = ax1.contour(w_axis,b_axis,mse, levels=cf.levels,colors=\"black\" ,linewidths=0.5)\n  fig.colorbar(cf, ax=ax1, label=\"MSE\")\n  ax2.set_axis_off()\n  ax1.set_xlabel(\"w\")\n  ax1.set_ylabel(\"b\")\n  ax1.set_title(\"Loss-Ground\")\n  ax1.plot(true_m, true_b, \"go\", ms=5, label=r\"true\")\n  ax1.plot(w_pred, b_pred, \"ro\", ms=5, label=\"prediction\")\n  ax1.legend()\n  return fig, ax1, ax2\n\n\n\nfigx, axx = surface_3d(term.w_mesh, term.b_mesh, mse_value,\"Loss Surface\", z_lim=0)\nfi4, ax1, ax2 = mse_contour(term.w_axis, term.b_axis, mse_value, w, b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSteigung der Funktion bei fixiertem b bzw. w. Wir k√∂nnen demensprechend eine horizontale bzw. vertikale in die Losssch√ºssel einzeichnen und merken schnell dass die Parameter unterschiedlichen Einfluss auf den MSE haben. Die Funktion auf der rechten Seite ist nichts anderes als die Visualiserung dieser Linien.\n\n\nCode\nfig5, ax1, ax2 = mse_contour(term.w_axis, term.b_axis, mse_value, w, b)\nFIXED_B = 1.5\nax1.axhline(FIXED_B, color=\"red\")\nax1.set_title(f\"fixed b = {FIXED_B}\")\n\ndef input_check(label: str):\n  lab = label.lower()\n  if lab not in {\"w\", \"b\"}:\n    raise ValueError(\"Input has to be w or b\")\n  return lab\n\ndef viz_mse_fixed_param(term: Calculator, ax_object,coord_x_axis, x_axis_label, param, title):\n  lab = input_check(x_axis_label)\n  if lab == \"w\":\n    mse_fix = term.mse(coord_x_axis, param * np.ones_like(coord_x_axis))\n  else:\n    mse_fix = term.mse(param * np.ones_like(coord_x_axis),coord_x_axis)\n  ax2.set_axis_on()\n  ax2.grid()\n  ax2.set_ylabel(\"MSE\")\n  ax2.set_xlabel(lab)\n  ax2.set_title(title)\n  ax2.plot(coord_x_axis, mse_fix)\n\nviz_mse_fixed_param(term, ax2, term.w_axis, \"w\", FIXED_B, f\"Loss with Fixed b = {FIXED_B}\")\n\nfig6, ax1, ax2 = mse_contour(term.w_axis, term.b_axis, mse_value, w, b)\nFIXED_W = float(1.5)\nax1.axvline(FIXED_W, color=\"red\")\nax1.set_title(f\"fixed w = {FIXED_W}\")\nviz_mse_fixed_param(term, ax2, term.b_axis, \"b\", FIXED_W, f\"Loss with Fixed w = {FIXED_W}\")",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#partielle-ableitungen-und-gradient-descent-in-1d",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#partielle-ableitungen-und-gradient-descent-in-1d",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.6 6. Partielle Ableitungen und Gradient Descent in 1D",
    "text": "2.6 6. Partielle Ableitungen und Gradient Descent in 1D\nUm zu verstehen, wie sich die Parameter \\(w\\) und \\(b\\) unabh√§ngig voneinander auf den Fehler auswirken, betrachten wir sie einzeln:\nLinker Plot: Zeigt den MSE-Verlauf in Abh√§ngigkeit von einem Parameter (\\(w\\) oder \\(b\\)), w√§hrend der andere fixiert bleibt.\nRechter Plot: Zeigt die zugeh√∂rige partielle Ableitung \\(\\frac{\\partial \\text{MSE}}{\\partial w}\\) bzw. \\(\\frac{\\partial \\text{MSE}}{\\partial b}\\).\nWir f√ºhren Gradient Descent Updates nur f√ºr einen Parameter durch, nach der Update-Regel:\n\\(\\text{Parameter}_{\\text{neu}} = \\text{Parameter}_{\\text{alt}} - \\alpha \\cdot \\frac{\\partial \\text{MSE}}{\\partial \\text{Parameter}}\\)\nwobei \\(\\alpha\\) die Lernrate ist.\nDer Gradient zeigt in die Richtung des steilsten Anstiegs, deshalb das - Vorzeichen, weil wir in Richtung des steilsten Abstiegs updaten.\n\n\nCode\n# ‚àÇMSE/‚àÇw bei fixem b\n# entkopplung von w und b sichtbar durch zentrieren\n\ndef viz_pderivate(term: Calculator, axis, fixed_param_value, label_x_axis):\n  lab = input_check(label_x_axis)\n  if lab == \"w\":\n    mse = term.mse(axis, fixed_param_value * np.ones_like(axis))\n    grad_component = term.grad_w(axis,fixed_param_value)\n    title_ = \"b\"\n  else:\n    mse = term.mse(fixed_param_value * np.ones_like(axis), axis)\n    grad_component = term.grad_b(fixed_param_value,axis)\n    title_ = \"w\"\n\n  fig, (axL, axR) = plt.subplots(1, 2, figsize=(14,4), constrained_layout=True)\n  axL.plot(axis, mse, alpha=0.6)\n  axL.set_xlabel(lab)\n  axL.set_title(f\"MSE with fixed ({title_}={fixed_param_value})\")\n  axL.set_ylabel(\"MSE\")\n  axR.plot(axis, grad_component)\n  axR.axhline(0, ls=\"--\", lw=1)\n  axR.set_xlabel(lab)\n  axR.set_ylabel(f\"‚àÇMSE/‚àÇ{lab}\")\n  axR.set_title(f\"‚àÇMSE/‚àÇ{lab}\")\n  return fig, (axL,axR), fixed_param_value\n\ndef viz_update(term: Calculator,\n               ax,\n               ax2,\n               update_trgt,\n               fixed_param_value,\n               label_x_axis,\n               learning_rate = 0.01,\n               n_loop=1\n               ):\n\n  lab = input_check(label_x_axis)\n  x , y, grad_list, step = [], [], [], []\n  counter = 0\n\n  for i in range(n_loop):\n\n    if lab == \"w\":\n      mse = term.mse(update_trgt, fixed_param_value)\n      grad_component = term.grad_w(update_trgt,fixed_param_value)\n    else:\n      mse = term.mse(fixed_param_value, update_trgt)\n      grad_component = term.grad_b(fixed_param_value,update_trgt)\n\n    x.append(update_trgt)\n    y.append(mse)\n    grad_list.append(grad_component)\n\n    #plot the start point\n    ax.plot(update_trgt, mse, \"go\", ms=3)\n\n    updadte_step = - (learning_rate * grad_component)\n    step.append(updadte_step)\n\n    update_trgt += updadte_step\n\n    #print(f\"mse = {y[i]} , grad = {grad_list[i]} , w = {x[i]}\")\n    if counter &gt;= 1:\n      ax.arrow(x[i-1], y[i-1], step[i-1], y[i] - y[i-1], color=\"red\", width=0.02, head_width=0.1,head_length=0.10,)\n\n\n    counter += 1\n  ax2.scatter(x,grad_list, c=\"red\", s=15)\n\n\n\n\nfig7,(ax1,ax2), param1 = viz_pderivate(term, term.w_axis, 0.5, \"w\" )\nfig8,(ax3,ax4), param2 = viz_pderivate(term, term.b_axis, 0.5, \"b\" )\n#0.13 max\nviz_update(term, ax1, ax2, 0, param1, \"w\", n_loop=8, learning_rate = 0.01)\nviz_update(term, ax3, ax4, 0, param2, \"b\", n_loop=8, learning_rate = 0.01)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#limitationen-der-globalen-lernrate-und-der-vereinfachten-update-regel",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#limitationen-der-globalen-lernrate-und-der-vereinfachten-update-regel",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.7 7. Limitationen der globalen Lernrate und der vereinfachten update Regel",
    "text": "2.7 7. Limitationen der globalen Lernrate und der vereinfachten update Regel\nAus den obigen Plots wird deutlich: Eine einzige, globale Lernrate \\(\\alpha\\) f√ºr alle Parameter ist selbst in diesem stark vereinfachten Szenario problematisch.\n\n2.7.0.1 Was wir hier stark vereinfacht haben ( die wichtigsten Punkte):\n1. Dimensionalit√§t: Nur 2 Modell Parameter statt Tausende bis Millionen\n2. Stochastizit√§t: Vollst√§ndiger Gradient auf allen Daten, kein Mini-Batch Rauschen\n3. Nicht-Konvexit√§t: Einfache konvexe Loss-Funktion mit einem globalen Minimum - Reale tiefe neuronale Netze sind Hochgradig nicht-konvex - Unz√§hlige lokale Minima - Sattelpunkte (Gradient = 0, aber kein Minimum) - Flache Plateaus (winzige Gradienten, kaum Fortschritt) - Schmale ‚ÄúT√§ler‚Äù und steile ‚ÄúKlippen‚Äù - Ill-conditioned Loss-Landschaften - Eine feste LR kann in flachen Regionen stecken bleiben oder in steilen Regionen ‚Äú√ºberschie√üen‚Äù\n4. Keine Vanishing/Exploding Gradients\n5. Keine Parameter-Abh√§ngigkeiten: \\(w\\) und \\(b\\) unabh√§ngig betrachtet\nTrotz dieser Vereinfachungen sehen wir bereits in unserem simplen 2D-Fall: - Unterschiedliche Parameter haben unterschiedliche Gradienten-Skalen - Eine Lernrate, die f√ºr \\(w\\) gut funktioniert, kann f√ºr \\(b\\) suboptimal sein - Die optimale Lernrate √§ndert sich w√§hrend des Trainings (gro√ü am Anfang, kleiner am Ende)\nAusblick:\nAber nicht verzweifeln, wenn dir die Begriffe erstmal nichts sagen. Im Laufe meines Kurses werden wir uns damit genauer befassen. Hier geht es erstmal nur darum dir eine Intuition aufzubauen, im hierauf aufbauenden Notebook werden wir uns den Weg vom GD zum Stochastic Gradient Descent und anderen Optimizern ansschauen, sowie Strategien wie man die lr anpasst.\n\n\n2.7.1 Unterschiedliche Lernraten\nNun schauen wir uns mal an was passiert wenn wir unsere lr erh√∂hen.\n\n\nCode\nterm2 = Calculator(x_train,y_train,start_axis=-20,stop_axis=20)\nfig5,(ax9,ax10), param3 = viz_pderivate(term, term.w_axis, 0.5, \"w\" )\nfig6,(ax11,ax12), param4 = viz_pderivate(term, term.w_axis, 0.5, \"w\" )\nfig7,(ax13,ax14), param5 = viz_pderivate(term2, term2.w_axis, 0.5, \"w\" )\n#0.13 max\nviz_update(term, ax9, ax10, 0, param3, \"w\", n_loop=8, learning_rate = 0.11)\nviz_update(term, ax11, ax12, 0, param4, \"w\", n_loop=8, learning_rate = 0.12)\nviz_update(term2, ax13, ax14, 0, param5, \"w\", n_loop=10, learning_rate = 0.13)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.2 Erkenntnis:\n\nIm ersten Plot erkennen wir dass das minimum √ºbersprungen wird, jedoch die Parametupdates trotzdem zum MSE minimum konvergieren\nIm zweiten Plot mit etwas h√∂herer lr konvergiert das Modell trotzdem nur ist unser updatestep so stark, dass wir das Minimum viel weiter √ºberschiessen als im Plot zuvor und sich dadurch der gradient nicht schnell genung sinkt. Das training kommt sehr langsam voran. Auch wenn wenn wir hier nur eine simple Loss Oberfl√§che haben, wird beim gedanklichen √úbertrag, deutlich dass es bei hochgradig nicht konvexen und hochdimensionalen Oberfl√§chen es keine gute Idee ist unsere Parameter unkontrolliert zu updaten\nIm dritten Plot ist sorgt die lr daf√ºr dass unser gradient explodiert und wir vom Minimum divergieren.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#chainrule",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#chainrule",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.8 8. Chainrule",
    "text": "2.8 8. Chainrule\nMithilfe der Kettenregel k√∂nnen wir den Gradienten berechnen. Wir werden das ausf√ºhlich im Notebook Backpropagation behandeln, sobald wir bei tiefen neuronalen Netzten angekommen sind. \\[\n\\Large\n\\begin{aligned}\n\\nabla_{w,b}\\,\\text{MSE} &=\n\\begin{bmatrix}\n\\dfrac{\\partial\\,\\text{MSE}}{\\partial w} \\\\\n\\dfrac{\\partial\\,\\text{MSE}}{\\partial b}\n\\end{bmatrix}\n=\n\\frac{2}{n}\n\\sum_{i=1}^{n}\n\\begin{bmatrix}\nx_i(\\hat{y_i} - y_i) \\\\\n(\\hat{y_i} - y_i)\n\\end{bmatrix}\n\\\\[1em]\n\\frac{\\partial{\\text{MSE}}}{\\partial{w}}\n&= \\frac{\\partial{\\text{MSE}}}{\\partial{\\hat{y_i}}}\n   \\frac{\\partial{\\hat{y_i}}}{\\partial{w}}\n= \\frac{2}{n} \\sum_{i=1}^n{x_i (\\hat{y_i} - y_i)}\n\\\\[0.8em]\n\\frac{\\partial{\\text{MSE}}}{\\partial{b}}\n&= \\frac{\\partial{\\text{MSE}}}{\\partial{\\hat{y_i}}}\n   \\frac{\\partial{\\hat{y_i}}}{\\partial{b}}\n= \\frac{2}{n} \\sum_{i=1}^n{(\\hat{y_i} - y_i)}\n\\end{aligned}\n\\]\n\n\nCode\n# With Chain rule C/z * z/w (or b)\ndef m_grad(x,y,y_hat):\n  return (2/len(y)) * ((y_hat-y) * x).sum()\n\ndef b_grad(y,y_hat):\n  return 2 * (y_hat-y).mean()\n\nlr = 0.01 # oder lr * 2 und die Ableitung vereinfachen von MSE 1/2n(...)\n\ndef update_target(target, gradient, lr=lr):\n  new_target = target - lr * gradient\n  return new_target",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#training",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#training",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.9 9. Training:",
    "text": "2.9 9. Training:\nWir trainieren das Modell √ºber 400 Epochen, die Kernidee: 1. Erstelle eine Prediction 2. Berechne den Loss der Prediction zu den True Werten aus dem Train Set 3. Berechne die 2 Komponenten des Gradienten 4. Update w und b mit einer lr von 0.01 5. Validiere nun anhand des Val Sets, verwende dabei die updated parameters\n\n\nCode\nepoch = 400\ntrain_loss, val_loss , pred_history = [], [], []\nw_path, b_path = [], []\n\ndef train(x_train,y_train,w,b):\n  y_hat = predict(x_train,w,b)\n  pred_history.append(y_hat)\n  loss = mse(y_train,y_hat)\n  mg = m_grad(x_train,y_train,y_hat)\n  bg = b_grad(y_train,y_hat)\n  w = update_target(w,mg)\n  b = update_target(b,bg)\n  w_path.append(w)\n  b_path.append(b)\n  return w,b,loss\n\ndef validate(x_val,y_val,w,b):\n  y_hat_val = predict(x_val, w, b)\n  v_loss = mse(y_val, y_hat_val)\n  return v_loss\n\n\nfor e in range(1,epoch+1):\n  w,b,t_loss = train(x_train,y_train,w,b)\n  v_loss = validate(x_val,y_val,w,b)\n  train_loss.append(t_loss)\n  val_loss.append(v_loss)\nprint(f\"trained w={w:4f}, trained b={b:4f}\")\n\n\n\ntrained w=1.986688, trained b=1.985263",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#visualisierung-des-loss",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#visualisierung-des-loss",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.10 10. Visualisierung des Loss",
    "text": "2.10 10. Visualisierung des Loss\nIm n√§chsten Schritt visualisieren wir den train und val loss. Selbst bei einem so simplen Problem gibt es uns ausschlussreiche Informationen welche wir daraus ableiten k√∂nnen. Wir sehen, dass das Modell zun√§chst schnell Richtung Optimum konvergiert. Anschlie√üend flacht die Kurve sichtbar ab, weil die Gradienten nahe des Minimums sehr klein werden und weitere Verbesserungen nur langsam erfolgen. Der nahezu identische Verlauf von Trainings- und Validierungs-Loss weist darauf hin, dass das Modell sehr gut generalisiert. Der verbleibende Fehler ist damit √ºberwiegend auf den Bias bzw. auf strukturelle Modellgrenzen oder Datenrauschen zur√ºckzuf√ºhren und l√§sst sich durch l√§ngeres Training praktisch nicht weiter reduzieren.\n\n2.10.0.1 Anmerkung:\nBeim Training tiefer neuronaler Netze steigt der Rechenaufwand schnell an, sodass lange Trainingsphasen sehr kostenintensiv werden k√∂nnen. F√ºr ein synthetisch generiertes Dataset wie in unserem Beispiel spielt das zwar keine gro√üe Rolle, in realen Szenarien jedoch schon. Eine g√§ngige Ma√ünahme zur Reduktion von Trainingszeit ist Early Stopping: Bleibt der Validierungs-Loss √ºber mehrere Epochen hinweg unterhalb eines festgelegten Verbesserungs-Schwellwerts, wird das Training automatisch beendet. Dadurch spart man Rechenzeit und verhindert unn√∂tige Optimierungsschritte, die nicht mehr zur Generalisierung beitragen.\nDer Effekt von Early Stopping auf bestimmte Trainingsdynamiken, wie z. B. das sogenannte , [Grokking](https://en.wikipedia.org/wiki/Grokking_(machine_learning) besprechen wir sp√§ter separat.\n\n\nCode\ndef plot_loss(train_loss, val_loss):\n  fig, ax = plt.subplots(figsize=(7,4))\n  ax.plot(train_loss, c=\"red\", label=\"Train Loss\")\n  ax.plot(val_loss, c= \"green\", label =\"Validation Loss\")\n  ax.legend()\n  ax.set_title(\"Loss History\")\n  ax.grid()\n  ax.set_ylabel(\"Loss\")\n  ax.set_xlabel(\"Epoch\")\n\nplot_loss(train_loss, val_loss)\n\n\n\n\n\n\n\n\n\n\n\nCode\nw_path = np.array(w_path)\nb_path = np.array(b_path)\n\nassert(\n    np.min(w_path) &gt;= np.min(term.w_axis)\n    and np.max(w_path) &lt;= np.max(term.w_axis)\n) ,\"Path can't be fully shown, rearrange the term w axis\"\n\n\nassert(\n    np.min(b_path) &gt;= np.min(term.b_axis)\n    and np.max(b_path) &lt;= np.max(term.b_axis)\n), \"Path can't be fully shown, rearrange the term b axis\"\n\n\n\n\n2.10.1 Update Pfad\nIn unserer ‚ÄúLoss-Sch√ºssel‚Äù k√∂nnen wir den update Pfad einzeichnen. Wie wir schon im GD in 1d beobachtet haben, konvergiert w schneller richtung minimum als b.\n\n\nCode\nfi4, ax1, ax2 = mse_contour(term.w_axis, term.b_axis, mse_value, w, b)\n\ndef viz_path(ax1,w_path,b_path):\n  ax1.plot(w_path, b_path, \".-\", lw=0.5, ms=2, color=\"w\", label=\"Update-Path\")\n  ax1.plot(w_path[0], b_path[0], \"wo\", ms=6, label=\"Start\")\n  ax1.legend()\n\nviz_path(ax1,w_path,b_path)\n\n\n\n\n\n\n\n\n\nHier sehen wir, wie das Modell predicted. Wir k√∂nnen da sehr sch√∂n das lernverhalten mit unterschiedlicher lr beobachten. Einfach daf√ºr die lr im Notebook erh√∂hen und die ensprechenden Zellen ausf√ºhren.\n\n\nCode\ndef timelapse(x,y,predictions,showtime=0.2):\n  fig, ax = plt.subplots(figsize=(7,4))\n  ax.scatter(x, y, s=3, c=\"red\", label=\"noise\")\n  ax.grid()\n  ax.set_xlabel(\"x\")\n  ax.set_ylabel(\"prediction\")\n  pred_plot = ax.scatter(x, predictions[0], s=1, c=\"blue\", label=\"pred\")\n  #ax.set_ylim(-100,100)\n  handle = display(fig, display_id=True)\n  for pred in predictions:\n    offset = np.column_stack((x,pred))\n    pred_plot.set_offsets(offset)\n    fig.canvas.draw_idle()\n    handle.update(fig)\n    plt.pause(showtime)\n\n\n#timelapse(x_train,y_train,pred_history)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#viszualize-gradient-norm",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#viszualize-gradient-norm",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.11 11. Viszualize Gradient Norm",
    "text": "2.11 11. Viszualize Gradient Norm\nDer Gradient ist ein Vektor, der an jedem Punkt \\((w, b)\\) in die Richtung des steilsten Anstiegs zeigt. In unserem Fall hat er zwei Komponenten: die partielle Ableitung nach \\(w\\) und nach \\(b\\). Diese Struktur macht eine direkte Visualisierung in 3D schwierig, wir m√ºssten an jedem Punkt zwei separate Pfeile oder einen Vektorpfeil zeigen, was schnell un√ºbersichtlich wird. Nat√ºrlich gibt es auch M√∂glichkeiten Losslandscapes in n-dimensionalen Parameterr√§umen vereinfacht darzustellen, aber das w√ºrde den Rahmen unseres Themas hier sprengen.\nStattdessen visualisieren wir die Gradient Norm, also die L√§nge des Gradienten-Vektors:\n\\[\\|\\nabla \\text{MSE}\\| = \\sqrt{\\left(\\frac{\\partial \\text{MSE}}{\\partial w}\\right)^2 + \\left(\\frac{\\partial \\text{MSE}}{\\partial b}\\right)^2}\\]\nDie Norm ist ein einzelner Skalar-Wert, der uns wichtige Informationen liefert: Sie misst, wie stark sich die Loss-Funktion an dieser Stelle ver√§ndert, unabh√§ngig von der konkreten Richtung. Eine gro√üe Norm bedeutet, dass wir uns in einer steilen Region befinden, egal ob die Steigung von \\(w\\), von \\(b\\), oder von beiden kommt. Eine kleine Norm hingegen signalisiert eine flache Region, und im Minimum, Maximum sowie an Sattelpunkten wird die Norm zu Null.\nDie Gradient Norm bestimmt direkt die Schrittgr√∂√üe beim Gradient Descent Update: In Regionen mit gro√üer Norm (steile H√§nge) macht dieser vereinfachte Algorithmus gro√üe Schritte, w√§hrend er in flachen Regionen nur kleine Schritte macht. Das sehen wir aus der Visualisierung.\n\n\nCode\nterm.set_mesh(0,4,n=100)\ndb = term.grad_b(term.w_mesh,term.b_mesh)\ndw = term.grad_w(term.w_mesh,term.b_mesh)\nnorm = np.sqrt(dw**2 + db**2)\n\n#gradienpath\nw_path = np.array(w_path)\nb_path = np.array(b_path)\ndw_path = term.grad_w(w_path, b_path)\ndb_path = term.grad_b(w_path, b_path)\nnorm_path = np.sqrt(dw_path**2 + db_path**2)\n\ndef show_path(ax, w_path, b_path, path):\n  ax.plot(w_path,b_path,path,marker=\"o\",ms=1,linestyle=\"-\",linewidth=1,c=\"green\", zorder=10)\n  ax.scatter(w_path[0],  b_path[0],  path[0] + 0.001,  s=50, c=\"b\", label=\"start\", zorder=11)\n  ax.scatter(w_path[-1], b_path[-1], path[-1] + 0.001, s=50, c=\"r\",label=\"end\", zorder=11)\n  ax.legend()\n\n\nfig9,ax9 = surface_3d(term.w_mesh,term.b_mesh,norm,\"Gradient Norm\",z_lim=0)\nax9.view_init(elev=55, azim=60)\nshow_path(ax9,w_path,b_path,norm_path)\n\nz0 = np.zeros_like(term.w_mesh)\nax9.plot_surface(\n    term.w_mesh,\n    term.b_mesh,\n    z0,\n    alpha=0.2,\n    linewidth=0,\n    antialiased=True,\n)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#visualisierung-der-gradientenkomponenten",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#visualisierung-der-gradientenkomponenten",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.12 12. Visualisierung der Gradientenkomponenten",
    "text": "2.12 12. Visualisierung der Gradientenkomponenten\nIn diesen Visualisierungen wird die jeweilige Gradientenkomponente \\(\\frac{\\partial L}{\\partial w}\\) bzw. \\(\\frac{\\partial L}{\\partial b}\\) dargestellt. Die H√∂he der Oberfl√§che zeigt also nicht den Loss an, sondern ausschlie√ülich den Wert der entsprechenden Ableitung an jedem Punkt des Parameterraums.\nDie dargestellte Fl√§che gibt damit Auskunft dar√ºber, wie stark und in welche Richtung sich die Loss-Funktion lokal ver√§ndert.\n\n\nCode\nfig10,ax10 = surface_3d(term.w_mesh,term.b_mesh,db,\"Gradient Component b\")\nshow_path(ax10,w_path,b_path,db_path)\n\nfig11,ax11 = surface_3d(term.w_mesh,term.b_mesh,dw,\"Gradient Component w\")\nshow_path(ax11,w_path,w_path,dw_path)\nax11.view_init(elev=45, azim=120)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHiermit haben wir das Thema Gradientenabstieg behandelt und k√∂nnen nun verstehen wie wir dadurch sp√§ter neuronale Netze nur diesmal mit Aktivierung trainieren. Da wir hier ein lineares Modell beschreiben k√∂nnen wir das einfach auch analytisch l√∂sen mit der Methode der kleinsten Quadrate.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#lineares-modell-und-designmatrix",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#lineares-modell-und-designmatrix",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.13 13. Lineares Modell und Designmatrix",
    "text": "2.13 13. Lineares Modell und Designmatrix\nWir betrachten ein lineares Regressionsmodell. Linear in diesem Kontext bedeutet f√ºr uns nicht eine Gerade, sondern bezieht sich auf den Parameterraum \\(w\\). Der Featureraum \\(X\\) kann nichtlinear sein, beispielsweise \\([1,\\; x,\\; x^2]\\).\nDa wir in unserem Fall eine lineare Gleichung approximieren wollen, mit\n\\[f(x) = m \\cdot x + b,\\]\nbewegen wir uns in einem zweidimensionalen Parameterraum ‚Üí \\(w_1 \\cdot x + w_0 \\cdot 1\\).\nNat√ºrlich k√∂nnte man diesen erweitern, jedoch muss eine Semantik dahinterstecken. Beispielsweise w√§re\n\\[w_2 \\cdot x_1 + w_1 \\cdot x_1 + w_0 \\cdot 1\\]\nnichts anderes als\n\\[(w_2 + w_1) \\cdot x_1 + w_0 \\cdot 1.\\]\nDas ist problematisch, da wir nun in der Designmatrix eine lineare Abh√§ngigkeit geschaffen haben. Dadurch ist \\(\\Phi^\\top \\Phi\\) nicht mehr garantiert invertierbar, weil\n\\[\\operatorname{rank}(\\Phi) &lt; D+1.\\]\nDas Gleichungssystem h√§tte dann unendlich viele L√∂sungen, und die folgende Gleichung k√∂nnte nicht mehr verwendet werden und wir m√ºssten einen anderen Ansatz w√§hlen.\nEs gibt Wege, wie man den Feature-Raum √ºber Feature-Engineering sinnvoll erweitern kann. Das werden wir uns jedoch in einem sp√§teren Kapitel anschauen.\n\\[\n\\hat{y} = f(x; w) = w_0 + w_1 x_1 + \\dots + w_D x_D = w^T \\phi(x)\n\\]\nmit\n\\[\n\\phi(x) =\n\\begin{pmatrix}\n1 \\\\\nx_1 \\\\\n\\vdots \\\\\nx_D\n\\end{pmatrix},\n\\quad\nw =\n\\begin{pmatrix}\nw_0 \\\\\nw_1 \\\\\n\\vdots \\\\\nw_D\n\\end{pmatrix}\n\\]\nF√ºr \\(n\\) Datenpunkte fassen wir alle Feature-Vektoren zu einer Designmatrix \\(\\Phi\\) zusammen:\n\\[\n\\Phi =\n\\begin{pmatrix}\n\\phi(x_1)^T \\\\\n\\phi(x_2)^T \\\\\n\\vdots \\\\\n\\phi(x_n)^T\n\\end{pmatrix}\n\\in \\mathbb{R}^{n \\times (D+1)}\n\\]\nDann gilt kompakt\n\\[\n\\hat{y} = \\Phi w\n\\]\n\n\nCode\ndef design_matrix(x):\n  x = np.column_stack((np.ones_like(x),x))\n  return x\n\nphi_train = design_matrix(x_train)\nphi_val = design_matrix(x_val)",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/gradient_descent/01_gd_fundamentals.html#fehlerfunktion-ssemse-und-normalengleichungen",
    "href": "docs/beginner/gradient_descent/01_gd_fundamentals.html#fehlerfunktion-ssemse-und-normalengleichungen",
    "title": "2¬† Introduction Gradient Descent",
    "section": "2.14 14. Fehlerfunktion (SSE/MSE) und Normalengleichungen",
    "text": "2.14 14. Fehlerfunktion (SSE/MSE) und Normalengleichungen\nWir definieren die Summe der Fehlerquadrate (SSE) als\n\\[\nO(w) = \\sum_{i=1}^n (y_i - w^T \\phi(x_i))^2\n     = \\| y - \\Phi w \\|^2\n     = (y - \\Phi w)^T (y - \\Phi w)\n\\]\nWie wir unschwer ekennen ist der MSE, nicht anderes als eine skalierung des SSE um 1/n.¬†Da sich dadurch das Minimum nicht ver√§ndert, k√∂nnen wir uns die Lossoberfl√§che im oberen Abschnitt anschauen. Dort wird deutlich, dass mit der Konvexit√§t, die wichtigste Eigenschaft der Loss Funktion f√ºr den Ansatz erf√ºllt ist.\n\\[\n\\tilde{O}(w) = \\frac{1}{2} \\| y - \\Phi w \\|^2\n\\]\nDie Ableitung nach \\(w\\) ergibt:\n\\[\n\\nabla_w \\tilde{O}(w)\n= \\Phi^T \\Phi w - \\Phi^T y\n\\]\nMinimum: setze \\(\\nabla_w \\tilde{O}(w) = 0\\):\n\\[\n\\Phi^T \\Phi w = \\Phi^T y\n\\]\nDas sind die Normalengleichungen. Falls \\(\\Phi^T \\Phi\\) invertierbar ist:\n\\[\n\\hat{w} = (\\Phi^T \\Phi)^{-1} \\Phi^T y\n\\]\n\n\nCode\nw_hat = np.linalg.inv(phi_train.T @ phi_train) @ phi_train.T @ y_train\nprint(f\"w_hat = {w_hat}\")\nprint(f\"The parameters we calculated with gradient descent: bias Term: {b}, w0: {w}\")\n\n\nw_hat = [1.98562596 1.98668856]\nThe parameters we calculated with gradient descent: bias Term: 1.9852628900702307, w0: 1.9866878917864874\n\n\nEs ist unschwer zu erkennen, dass wir mit beiden Methoden sehr identische Parameter bekommen haben. Das liegt daran dass wir beim Gradientenabstieg einen iterrativen Optimierungsverfahren benutzen der unsere zuf√§liig initilaliserten Parameter zu einem niedrigeren Loss konvergieren l√§sst. Hier wird es analytisch berechnet. Aussage 2 haben wir damit untermauert.\n\n\nDurch das hinzuf√ºgen von normalverteilten Rauschen ist der Fehler selbst bei wahren Parametern nicht mehr 0 (true_m, true_b) . Das hei√üt unsere optimalen Modell Parameter unterscheiden sich von den ‚Äúwahren‚Äù Werten.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Introduction Gradient Descent</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#auswertung",
    "href": "docs/beginner/Perceptron.html#auswertung",
    "title": "1¬† Perceptron",
    "section": "1.9 Auswertung",
    "text": "1.9 Auswertung\nAuf dem ersten Blick ist sichtbar, dass das Modell nicht zur minimal m√∂glichen Error rate von 0.25 konvergiert(eine Fehlklassifikation). Das hat den einfachen Grund dass wir mit dem Perzeptron kein Optimierungsproblem l√∂sen. Die implemtierte Lernregel besagt n√§mlich im Kern, trainiere so lange weiter bis du die Klassen seperieren kannst oder die maximale Anzahl an Epochen erreicht sind.\nDamit ist zwar das Verhalten der Error rate erkl√§rt aber nicht wieso die Entscheidungsgrenze sich ab der 20 Epoche nicht mehr ver√§ndert.\nUm das zu verstehen, brauchen wir erstmal eine kleine visuelle Einordung der Timelapse und der Modellparameter. Was wir sehen ist immer ein Snapshot des Modellzustandes zum Ende einer Epoche. Also der Zustand der nach dem Update des letzen sampels zustande gekommen ist, hier Feauture -&gt; (1,1).\nDie konstante updaterate von 1 impliziert das jedes Trainingsample f√ºr das darauf folgende Sample ein update ausgel√∂st hat, also ein delta != 0. Die Gewichte haben sich somit unweigerlich ver√§ndert, nur wurde wurde es wieder √ºberschrieben, da das delta dauernd zwischen -1 und 1 schwingt. Das wird aus der update Regel auch deutlich, welche auch auf den Bias √ºbertragen werden kann. \\[\n\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta \\, \\delta \\, \\mathbf{x}\n\\]",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#ausblick",
    "href": "docs/beginner/Perceptron.html#ausblick",
    "title": "1¬† Perceptron",
    "section": "1.10 Ausblick",
    "text": "1.10 Ausblick\nIm n√§chsten Kapitel machen wir mit dem logistischen Perzeptron weiter, daf√ºr verwenden wir die oben definierte Sigmoid Aktivierungsfunktion. Damit werden 2 fundamentale √Ñnderungen an unserem Modell durchgef√ºhrt, die uns den Weg zum Multi Layer Perzeptron vereinfachen werden. Wir werden damit Anfangen ein Optimierungsproblem zu l√∂sen. Au√üerdem wird das Prinzip der Unsicherheit eingef√ºhrt. Die Ausgabe des Rosenblatt Perzeptrons ist bin√§r, im √ºbertragenen Kontext mit Blick auf Unsicherheit bedeutet es, dass das Perzeptron in seiner Prediction immer zu 100% sicher ist auch wenn diese falsch ist.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#the-perceptron-as-a-model",
    "href": "docs/beginner/Perceptron.html#the-perceptron-as-a-model",
    "title": "1¬† Perceptron",
    "section": "1.2 The perceptron as a model",
    "text": "1.2 The perceptron as a model\nThe perceptron processes inputs in three consecutive steps:\n\n1.2.1 1. Input\nThe model receives an input vector x, we call this the feature vector.\n\n\n1.2.2 2. Calculation\nThe input is linearly transformed using the weights w and the bias parameter b. We call the weighted sum z:\n\\[z = \\mathbf{w}^\\top \\mathbf{x} + b\\]\n\n\n1.2.3 3. Output\nWe pass the weighted sum z to a non-linear activation function, which in the Rosenblatt perceptron is classically the step function. In the perceptron, we call the result of this the prediction of the model:\n\\[\\hat{y} = \\text{step}(z) = \\begin{cases} 1 & \\text{if } z \\geq 0 \\\\ 0 & \\text{otherwise} \\end{cases}\\]\n\n\n1.2.4 Complete data flow\nThe entire process can be represented as follows:\n\\[\\mathbf{x} \\longrightarrow \\mathbf{w}^\\top \\mathbf{x} + b \\longrightarrow \\text{step}(z) \\longrightarrow \\hat{y}\\]\n\n\n\nCode\npth = Path(\"illustrations\") / \"beginner\" / \"perceptron\"\nfig3, ax3 = show_illustration(\n    pth / \"perceptron.ppm\", pth / \"perceptron_source.txt\"\n)\n\n\n\n\n\n\n\n\n\nDefining the activation function\nIn addition to the step function just defined, we will now also introduce the sigmoid activation function, which we will use later with a modified learning rule for the perceptron and the multi-layer perceptron. In deep learning, there are a variety of different activations, some of which we will look at as we go along.\nA visual inspection immediately reveals some properties that are directly visible, but there are also hidden properties that cannot be recognised directly by sharp eyes. This is irrelevant for us at the moment, as we first want to develop an intuition for the workflow. We will examine this in more detail in the Activation and Feature Space chapters of the Beginners Section and later in the Intermediate Section.\nSigmoid: \\[ f(x)=\\frac{1}{1+e^{-x}} \\]\nYou can see at a glance that: - The value range is in (0,1) - Monotonically increasing - For large |x|, the value approaches 0 or 1 - Continuously differentiable\nThe output of the sigmoid function can be given semantics. For binary classification, this means: - \\(\\sigma(z) &lt; 0.5\\) ‚Üí Class 0 - \\(\\sigma(z) &gt;= 0.5\\) ‚Üí Class 1\nStep function:\nYou can see at a glance: - Values can only be 0 or 1 - x = 0 is not defined - even if differentiable, slope = 0 -&gt; no usable gradient -&gt; no information content\n\n\nCode\ndef step_function(x: np.ndarray):\n  return np.where(x &gt;= 0, 1, 0)\n\ndef sigmoid(x: np.ndarray):\n  return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x: np.ndarray):\n  ds = (np.exp(-x))/(1+np.exp(-x))**2\n  return ds\n\nx = np.linspace(-10, 10, 100)\nfig4, ax4 = plt.subplots(figsize=(7, 4))\n\nax4.plot(x, sigmoid(x), c=\"blue\", label=\"Sigmoid\")\nax4.plot(x, sigmoid_derivative(x), c=\"red\", label=\"Sigmoid derivative\")\nax4.plot(x[x &lt; 0], step_function(x[x &lt; 0]), c=\"orange\", label=\"Step Function\")\nax4.plot(x[x &gt;= 0], step_function(x[x &gt;= 0]), c=\"orange\")\n\nax4.grid(alpha=0.3)\nax4.set_xlabel(\"x\")\nax4.set_ylabel(\"f(x)\")\nax4.legend();",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#implementing-the-perceptron-class",
    "href": "docs/beginner/Perceptron.html#implementing-the-perceptron-class",
    "title": "1¬† Perceptron",
    "section": "1.3 Implementing the perceptron class",
    "text": "1.3 Implementing the perceptron class\nNow we will implement the perceptron as a class. We have already examined the architecture, so now we will focus on the learning rule.\n\n1.3.1 Classic perceptron learning rule\nThe perceptron learns by adjusting its weights only when it makes a mistake.\nFor each training example, the prediction \\(\\hat{y}\\) is compared with the true label \\(y\\).\nThis results in an error term:\n\\[\n\\delta = y - \\hat{y}\n\\]\n\nIf \\(\\delta = 0\\):\nThe prediction is correct ‚Üí no adjustment.\nIf \\(\\delta = 1\\):\nThe perceptron predicted \\(0\\) although \\(1\\) would be correct ‚Üí\nThe weights should be shifted in the direction of \\(\\mathbf{x}\\).\nIf \\(\\delta = -1\\):\nThe perceptron predicted \\(1\\) although \\(0\\) would be correct ‚Üí\nThe weights should be shifted away from \\(\\mathbf{x}\\).\n\nThe classical perceptron learning rule is:\n\\[\n\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta \\, \\delta \\, \\mathbf{x}\n\\]\n\\[\nb \\leftarrow b + \\eta \\, \\delta\n\\]\nwhere \\(\\eta\\) is the learning rate.\n\n1.3.1.1 Intuition\n\nIncorrectly classified positive examples (\\(y = 1\\)) ‚Äòpull‚Äô the weight vector in their direction.\nIncorrectly classified negative examples (\\(y = 0\\)) ‚Äòpush‚Äô the weight vector away from themselves.\nCorrectly classified examples have no influence on the weights.\n\nIn this way, the perceptron shifts its decision boundary until all training points (if linearly separable) are correctly classified.\n\n\n\nCode\nclass Perzeptron:\n    def __init__(self, input_size, activation_function):\n\n        self.weight = rng.normal(size=(input_size,1))\n        self.bias = 0.\n        self.activation = activation_function\n\n    def forward(self, X):\n        \"\"\"\n        Berechnet die Ausgabe des Perzeptrons f√ºr ein Feauture X.\n\n        Args:\n            X: Eingabedaten, Shape (n_samples, n_features)\n        Returns:\n            Ausgabe des Perzeptrons nach Aktiverung, Shape (n_samples, 1)\n        \"\"\"\n        z = X @ self.weight + self.bias\n        a = self.activation(z)\n        return a\n\n    def train(self, X, y , lr=0.1, epochs=1000, error_prints=True):\n        \"\"\"\n        Trains the perceptron using the perceptron (error-count) learning rule.\n\n        Args:\n            X (np.ndarray): Input data of shape (n_samples, n_features).\n            y (np.ndarray): Target labels of shape (n_samples, 1) \n            lr (float): Learning rate\n            epochs (int): Maximum number of training epochs.\n            error_prints (bool) : Printing error rates -&gt; set False for timelapse\n\n        Returns:\n            list[float]: List of error_rate per epoch\n            list[float]: List of update_rate per epoch\n        \"\"\"\n    \n        error_history, update_history = [], []\n\n        for epoch in range(epochs):\n            fehler_count = 0\n            for xi, yi in zip(X,y):\n                xi = np.reshape(xi, (1,-1)) # (1, n_features)\n                yi = np.reshape(yi, (-1,1)) # (1, 1) \n                #Forward pass \n                y_hat = self.forward(xi)\n\n                #Calc delta\n                delta = (yi - y_hat)\n                delta = np.squeeze(delta)\n                delta = float(delta)\n\n                #Update weights and bias\n                if delta != 0:\n                    self.weight += lr * delta * xi.T\n                    self.bias += lr * delta\n                    fehler_count += 1\n\n            update_rate = fehler_count/len(y)\n            y_hat = self.forward(X)\n            error_rate = float(np.mean(y != y_hat))\n            error_history.append(error_rate)            \n            update_history.append(update_rate)\n\n            if error_prints:\n                if epoch % 10 == 0:\n                    print(f'Epoch {epoch}: Error Rate = {error_rate:.4f}')\n\n            if error_rate == 0:\n                print(f\"Solution in Epoch {epoch}\")\n                return error_history, update_history\n                \n        return error_history, update_history",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#the-primary-problem",
    "href": "docs/beginner/Perceptron.html#the-primary-problem",
    "title": "1¬† Perceptron",
    "section": "1.4 The primary problem",
    "text": "1.4 The primary problem\nOver the course of the course, we will build many different architectures from scratch. These architectures are becoming increasingly complex, and we will have no choice but to deal with bugs and, even worse, ‚Äòhidden‚Äô errors, which can arise, for example, from incorrect shapes or unexpected NumPy broadcasting. So here is an example of how I tested the training loop implemented by Scratch.\nBroadcasting can make our lives a lot easier and is often good at guessing what we mean, for example in a line like z = X @ self.w + self.b. But this can also lead to us discovering errors very late, because the code runs, but silently does something different than intended.\nUnfortunately, we only have the presentation layer here, not what happens live on my end, so here is my personal ‚Äògo-to‚Äô for reducing frustration a bit (I still run into bugs occasionally üòÖ). If you have any improvements for me, I‚Äôm open to them!!!\nIn our workflow, we currently have roughly: Create data ‚Üí Define model ‚Üí Training.\n\nInspect the shapes of the data:\nLook at the shapes of X and y:\nDo they really match what you have in mind?\nE.g. X.shape == (n_samples, n_features), y.shape == (n_samples, 1).\nCheck the shapes of the model:\nCheck w, b and the output of forward:\nDo the dimensions match your data? Are there any obvious inconsistencies?\nRecord docstrings + shape conventions:\nWrite in the docstring of each method which shapes it works with\n(e.g.¬†X: (n_samples, n_features), return: (n_samples, 1))\nand stick to it. I have given a small example above.\nDummy forward pass:\nDo a single forward pass with small dummy data\n(e.g.¬†1‚Äì2 samples) and only check the shapes of the intermediate values:\nprint(X.shape, w.shape, z.shape, a.shape, ...).\nAssertions & Prints in Training:\nBecause we are defining our own training loop from scratch here -&gt; Simulate the training loop.\nIncorporate lots of assert statements (e.g.¬†assert y.shape == y_hat.shape)\nand debug prints to check whether the calculations are correct.\nStart small:\nTest new architecture ideas that you want to build from scratch with small model architectures, build your code modularly and then expand it.\nRestart session:\nIf you are working with ipynb files like here, restart the environment to clear the environment variables. This is the mistake I‚Äôve seen others make most often.\nDebugger:\nFor me, the debugger is my last line of defence. For beginners, I recommend Thonny for this (not trying to advertise XD).\nConsole:\nUse the console to do quick checks.\n\nConclusion: Write your tests, here is an example from me. Later, you can also add pytests, but for beginners in Python, this structure should be sufficient for now.\n\n\nCode\ndef test_train(model:Perzeptron, X:np.ndarray, y:np.ndarray , lr=0.1, epochs=1):\n    \"\"\"\n    Trains the perceptron using the perceptron (error-count) learning rule.\n\n    Args:\n        X (np.ndarray): Input data of shape (n_samples, n_features).\n        y (np.ndarray): Target labels of shape (n_samples, 1) \n        lr (float): Learning rate\n        epochs (int): Maximum number of training epochs.\n\n    Returns:\n        list[float]: List of error_rate per epoch\n        list[float]: List of update_rate per epoch\n    \"\"\"\n    print(\"=== Dummy train debug ===\")\n    error_history, update_history = [], []\n    # Checks before loop\n    print(f\"X.shape = {X.shape}\")\n    print(f\"y.shape = {y.shape}\")\n    assert X.ndim == 2, \"X should be 2D: (n_samples, n_features)\"\n    assert y.ndim == 2, \"y should be 2D: (n_samples, 1)\"\n    assert X.shape[0] == y.shape[0], \"X and y must have the same number of samples\"\n\n    print(f\"model.w.shape = {model.weight.shape}\")\n    print(f\"model.b type  = {type(model.bias)}\")\n    \n    for epoch in range(epochs):\n        fehler_count = 0\n\n        for i, (xi, yi) in enumerate(zip(X, y)):\n            # Check xi yi shapes f.e without reshape yi has shape (1,)\n            print(f\"--- Sample {i} ---\")\n            xi = np.reshape(xi, (1, -1))   # (1, n_features)\n            yi = np.reshape(yi, (-1, 1))   # (1, 1)\n\n            print(f\"xi.shape: {xi.shape}, yi.shape: {yi.shape}\")\n            print(f\"xi: {xi}\")\n            print(f\"yi: {yi}\")\n\n            # Check Forward-Pass\n            y_hat = model.forward(xi)\n            print(f\"y_hat.shape: {y_hat.shape}\")\n            print(f\"y_hat: {y_hat}\")\n\n            assert yi.shape == (1, 1)\n            assert yi.shape == y_hat.shape, \"yi and y_hat must have the same shape\"\n            # Correctness of the output step function\n            assert np.all((y_hat == 0) | (y_hat == 1)), \"y_hat should be 0 or 1 for step activation\"\n\n            # Delta check\n            delta = yi - y_hat\n            print(f\"delta: {delta}, shape: {delta.shape}\")\n            delta = np.squeeze(delta)\n            delta = float(delta)\n            \n            # Update check\n            if delta != 0:\n                print(\"updating parameters\")\n                print(f\"w before update: {model.weight}\")\n                print(f\"b before update: {model.bias}\")\n\n                update_w = lr * delta * xi.T    # (n_features, 1)\n                assert update_w.shape == model.weight.shape\n\n                model.weight += update_w\n                model.bias += lr * delta\n\n                print(f\"w after update: {model.weight}\")\n                print(f\"b after update: {model.bias}\")\n\n                fehler_count += 1\n            else:\n                print(\"Correct classification, no update\")\n\n        update_rate = fehler_count/len(y)\n        y_hat = model.forward(X)\n        error_rate = float(np.mean(y != y_hat))\n        assert 0 &lt;= error_rate &lt;= 1, \"error_rate must be between 0 and 1\"\n\n        # Output type check even if np object would work too\n        assert isinstance(error_rate, (float)), \"error_rate must be float\"\n        assert isinstance(update_rate, (float)), \"update_rate must float)\"\n\n    print(\"=== End dummy ===\")\n\n\ntest_model = Perzeptron(X.shape[1], step_function)\ntest_train(test_model, X, y)\n\n\n=== Dummy train debug ===\nX.shape = (4, 2)\ny.shape = (4, 1)\nmodel.w.shape = (2, 1)\nmodel.b type  = &lt;class 'float'&gt;\n--- Sample 0 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[0. 0.]]\nyi: [[0.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[-1.]], shape: (1, 1)\nupdating parameters\nw before update: [[0.55326059]\n [0.21760061]]\nb before update: 0.0\nw after update: [[0.55326059]\n [0.21760061]]\nb after update: -0.1\n--- Sample 1 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[0. 1.]]\nyi: [[0.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[-1.]], shape: (1, 1)\nupdating parameters\nw before update: [[0.55326059]\n [0.21760061]]\nb before update: -0.1\nw after update: [[0.55326059]\n [0.11760061]]\nb after update: -0.2\n--- Sample 2 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[1. 0.]]\nyi: [[0.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[-1.]], shape: (1, 1)\nupdating parameters\nw before update: [[0.55326059]\n [0.11760061]]\nb before update: -0.2\nw after update: [[0.45326059]\n [0.11760061]]\nb after update: -0.30000000000000004\n--- Sample 3 ---\nxi.shape: (1, 2), yi.shape: (1, 1)\nxi: [[1. 1.]]\nyi: [[1.]]\ny_hat.shape: (1, 1)\ny_hat: [[1]]\ndelta: [[0.]], shape: (1, 1)\nCorrect classification, no update\n=== End dummy ===\n\n\n\n1.4.1 Training the perceptron\nNow we can train the model on our AND/OR data.\nWe are not only interested in whether the perceptron classifies everything correctly in the end, but also in how the error rate develops over the epochs.\nThe error rate is simply the proportion of training examples that were incorrectly classified in an epoch.\nTo do this, we visualise the error rate curve during training.\n\n\nCode\ndef visualize_training(error_history):\n    epochs = np.arange(1, len(error_history) + 1)\n    fig, ax = plt.subplots(figsize=(7, 4))\n\n    ax.plot(epochs,error_history, label=\"Error rate\", c=\"r\")\n    ax.set_xlabel(\"Epoch\")\n    ax.set_ylabel(\"Error rate\")\n    ax.set_title(\"Error rate progress\")\n    ax.legend()\n    return fig, ax\n\n\n\n\n\nCode\ninput_size = X.shape[1]\nmodel = Perzeptron(input_size, step_function)\nerror_history,_ = model.train(X, y, lr=0.1, epochs=100)\nfig5, ax5 = visualize_training(error_history)\n\n\nEpoch 0: Error Rate = 0.7500\nEpoch 10: Error Rate = 0.5000\nEpoch 20: Error Rate = 0.5000\nSolution in Epoch 25",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#evaluating-results",
    "href": "docs/beginner/Perceptron.html#evaluating-results",
    "title": "1¬† Perceptron",
    "section": "1.5 Evaluating results",
    "text": "1.5 Evaluating results\nNow let‚Äôs take a look at how the trained perceptron responds to the input data. Some readers will immediately realise that the predictions and expected output must be identical, as a solution was found before the termination condition was reached. The error rate for this model can only be one of the following values:\n1 (max error counter/4)\n0.75 -&gt; 3/4\n0.5 -&gt; 2/4\n0.25 -&gt; 1/4\n0 -&gt; 0/4\n\n\nCode\npredictions = model.forward(X)\nprint(\"Eingaben und Vorhersagen:\")\nfor i in range(len(X)):\n    print(f\"Eingabe: {X[i]}, Erwartete Ausgabe: {y[i]}, Vorhersage: {predictions[i]}\")\n\n\nEingaben und Vorhersagen:\nEingabe: [0. 0.], Erwartete Ausgabe: [0.], Vorhersage: [0]\nEingabe: [0. 1.], Erwartete Ausgabe: [0.], Vorhersage: [0]\nEingabe: [1. 0.], Erwartete Ausgabe: [0.], Vorhersage: [0]\nEingabe: [1. 1.], Erwartete Ausgabe: [1.], Vorhersage: [1]",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#the-mathematical-model",
    "href": "docs/beginner/Perceptron.html#the-mathematical-model",
    "title": "1¬† Perceptron",
    "section": "1.6 The mathematical model",
    "text": "1.6 The mathematical model\nWe can output the trained perceptron as a function. This helps us understand it, since neural networks, whether deep or not, are nothing more than mathematical models. Since the perceptron is so simple, we can look at the function to understand it better. Normally, we would examine the learned weights and biases. However, we will do that in a separate chapter.\n\n\nCode\nw_flat = model.weight.flatten()  \nw1, w2 = w_flat\nb = model.bias\nprint(f\"f(x1,x2) = step({w1:.3f}*x1 + {w2:.3f}*x2 + {b:.3f})\")\n\n\nf(x1,x2) = step(0.142*x1 + 0.081*x2 + -0.200)\n\n\n\n1.6.1 Visualising the decision boundary\nThe decision boundary here is the straight line in the feature space at which the perceptron ‚Äòswitches‚Äô from class 0 to class 1. However, we should not get too hung up on the geometric shape at this point, because in 3D feature space at the latest, we should be aware that we need a surface there.\nWe visualise the decision boundary here by calculating the model‚Äôs predictions on a grid of points (meshgrid) and displaying them with contourf. This shows that:\n\nThe prediction jumps from 0 to 1. There are no values in between, as we can also see from the colour bar.\nThe boundary always appears more staircase-like with smaller n, because we are only evaluating on a grid. At first glance, this contradicts the defined shape of the decision boundary, but these are simply the limitations of a plotter. I had the same problem with my own function plotter that I had programmed.\n\n\n\nCode\nn = 1000\nx1 = np.linspace(-0.1, 1.1, n)\nx2 = np.linspace(-0.1, 1.1, n)\nx1_grid, x2_grid = np.meshgrid(x1, x2)\nX_viz = np.c_[x1_grid.flatten(), x2_grid.flatten()]\nassert X_viz.shape == (n*n, 2), (\n    \"Shape Mismatch for forward pass -&gt; expect shape (samplesize,2)\"\n    )\n\ny_viz = model.forward(X_viz).reshape(n,-1)\nfig6, ax6 = visualize_data(X,y,\"Descision Boundary Step Function for AND\")\ncf = ax6.contourf(x1_grid, x2_grid, y_viz, levels=10, cmap='coolwarm', alpha=0.6, zorder=0)\nfig6.colorbar(cf, label=\"Prediction\");",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#training-for-the-or-problem",
    "href": "docs/beginner/Perceptron.html#training-for-the-or-problem",
    "title": "1¬† Perceptron",
    "section": "1.7 Training for the OR problem",
    "text": "1.7 Training for the OR problem\nLet us also examine this for the OR problem. Since this is also linearly separable, as stated at the beginning, a solution is also found.\n\n\nCode\ny = y_or\nmodel = Perzeptron(input_size, step_function)\nerror_history,_ = model.train(X, y, lr=0.1, epochs=100)\nfig7, ax7 = visualize_training(error_history)\n\n\nEpoch 0: Error Rate = 0.7500\nEpoch 10: Error Rate = 0.5000\nEpoch 20: Error Rate = 0.2500\nSolution in Epoch 23\n\n\n\n\n\n\n\n\n\n\n\nCode\ny_viz = model.forward(X_viz).reshape(n,-1)\nfig8, ax8 = visualize_data(X,y,\"Descision Boundary Step Function for OR\")\ncf = ax8.contourf(x1_grid, x2_grid, y_viz, levels=10, cmap='coolwarm', alpha=0.6, zorder=0)\nfig8.colorbar(cf, label=\"Prediction\");",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#evaluation",
    "href": "docs/beginner/Perceptron.html#evaluation",
    "title": "1¬† Perceptron",
    "section": "1.9 Evaluation",
    "text": "1.9 Evaluation\nAt first glance, it is clear that the model does not converge to the minimum possible error rate of 0.25 (one misclassification). The simple reason for this is that we are not solving an optimisation problem with the perceptron. The implemented learning rule essentially states: continue training until you can separate the classes or the maximum number of epochs has been reached.\nThis explains the behaviour of the error rate, but not why the decision boundary no longer changes after the 20th epoch.\nTo understand this, we first need a little visual classification of the timelapse and the model parameters. What we see is always a snapshot of the model state at the end of an epoch. In other words, the state that resulted after the last sample was updated, in this case Feature -&gt; (1,1).\nThe constant update rate of 1 implies that each training sample triggered an update for the following sample, i.e.¬†a delta != 0. The weights have therefore inevitably changed, but they have been overwritten again because the delta constantly fluctuates between -1 and 1. This is also clear from the update rule, which can also be applied to the bias. \\[\n\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta \\, \\delta \\, \\mathbf{x}\n\\]",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  },
  {
    "objectID": "docs/beginner/Perceptron.html#outlook",
    "href": "docs/beginner/Perceptron.html#outlook",
    "title": "1¬† Perceptron",
    "section": "1.10 Outlook",
    "text": "1.10 Outlook\nIn the next chapter, we will continue with the logistic perceptron, using the sigmoid activation function defined above. This will introduce two fundamental changes to our model that will simplify the path to the multi-layer perceptron. We will start by solving an optimisation problem. In addition, the principle of uncertainty will be introduced. The output of the Rosenblatt perceptron is binary and does not contain any information about how certain the model is. In contrast, the logistic model with sigmoid provides a continuous output in (0,1), which can be interpreted as probability and thus provides a measure of uncertainty. In the figurative context with regard to uncertainty, this means that the perceptron is always 100% certain in its prediction, even if it is wrong.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Perceptron</span>"
    ]
  }
]